2025-01-09 22:57:12,310 - device          : cuda:4
2025-01-09 22:57:12,310 - model           : resnet101
2025-01-09 22:57:12,310 - mlp             : 0
2025-01-09 22:57:12,310 - vae             : False
2025-01-09 22:57:12,310 - epochs          : 50
2025-01-09 22:57:12,310 - batch           : 16
2025-01-09 22:57:12,311 - lr              : 0.0001
2025-01-09 22:57:12,311 - crop            : 512
2025-01-09 22:57:12,311 - optimizer       : adam
2025-01-09 22:57:12,311 - biases          : False
2025-01-09 22:57:12,311 - focal_loss      : 0
2025-01-09 22:57:12,311 - activation      : softmax
2025-01-09 22:57:12,311 - class_weights   : False
2025-01-09 22:57:12,311 - norm_weights    : False
2025-01-09 22:57:12,311 - p               : 0.3
2025-01-09 22:57:12,319 - Dataset Creati
2025-01-09 22:57:12,320 - Training images: 5125
2025-01-09 22:57:12,320 - Validation images: 1031

2025-01-09 22:57:12,320 - Dataloader Creati
2025-01-09 22:57:12,320 - Training batches: 320
2025-01-09 22:57:12,320 - Validation batches: 128

2025-01-09 22:57:15,985 - Model: deeplabv3plus_resnet101

2025-01-09 22:57:16,050 - Modello caricato correttamente su cuda:4

2025-01-09 22:57:16,053 - Inizio del training
2025-01-09 22:57:16,053 - optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 1e-05
    maximize: False
    weight_decay: 0.0001
)
2025-01-09 22:57:16,053 - loss:      CrossEntropyLoss()
2025-01-09 22:57:16,053 - epochs:    15
2025-01-09 22:57:16,053 - name:      weights_0

2025-01-09 23:03:32,197 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-09 23:03:32,198 - 0        0.944662   0.659522   0.291738   0.000000   0.819384   1.0e-04 , 1.0e-05 
2025-01-09 23:09:48,179 - 1        0.676938   0.625854   0.312860   0.000000   0.830433   1.0e-04 , 1.0e-05 
2025-01-09 23:09:48,180 - > saved mIoU
2025-01-09 23:16:04,358 - 2        0.615993   0.612119   0.328058   0.000000   0.832100   1.0e-04 , 1.0e-05 
2025-01-09 23:16:04,359 - > saved mIoU
2025-01-09 23:22:22,306 - 3        0.571141   0.603817   0.336834   0.000000   0.836502   1.0e-04 , 1.0e-05 
2025-01-09 23:22:22,307 - > saved mIoU
2025-01-09 23:28:38,486 - 4        0.554540   0.591227   0.344202   0.000000   0.842348   1.0e-04 , 1.0e-05 
2025-01-09 23:28:38,487 - > saved mIoU
2025-01-09 23:34:54,114 - 5        0.538391   0.602319   0.349403   0.010683   0.837210   1.0e-04 , 1.0e-05 
2025-01-09 23:34:54,114 - > saved mIoU
2025-01-09 23:41:11,325 - 6        0.517434   0.597676   0.359426   0.011409   0.841383   1.0e-04 , 1.0e-05 
2025-01-09 23:41:11,325 - > saved mIoU
2025-01-09 23:47:28,000 - 7        0.504158   0.584866   0.369738   0.015663   0.844831   1.0e-04 , 1.0e-05 
2025-01-09 23:47:28,000 - > saved mIoU
2025-01-09 23:53:47,193 - 8        0.493170   0.590359   0.378898   0.018220   0.844867   1.0e-04 , 1.0e-05 
2025-01-09 23:53:47,194 - > saved mIoU
2025-01-10 00:00:06,024 - 9        0.480333   0.591473   0.385278   0.019868   0.849316   1.0e-04 , 1.0e-05 
2025-01-10 00:00:06,024 - > saved mIoU
2025-01-10 00:06:23,939 - 10       0.473286   0.592047   0.396245   0.024939   0.851494   1.0e-04 , 1.0e-05 
2025-01-10 00:06:23,940 - > saved mIoU
2025-01-10 00:12:44,423 - 11       0.466107   0.597595   0.394075   0.025841   0.845439   1.0e-04 , 1.0e-05 
2025-01-10 00:19:05,922 - 12       0.461135   0.601673   0.403504   0.026411   0.847098   1.0e-04 , 1.0e-05 
2025-01-10 00:19:05,923 - > saved mIoU
2025-01-10 00:25:22,921 - 13       0.449658   0.595824   0.408243   0.030516   0.849333   1.0e-04 , 1.0e-05 
2025-01-10 00:25:22,921 - > saved mIoU
2025-01-10 00:31:40,362 - 14       0.451699   0.611676   0.407445   0.030273   0.848284   1.0e-04 , 1.0e-05 
2025-01-10 00:31:40,363 - Fine del training

2025-01-10 00:31:40,630 - 
Caricati i pesi in: /raid/homespace/piecestola/space/ML4CV/results/train_4/ckpts/weights_mIoU_0.pt

2025-01-10 00:31:40,631 - Inizio del training
2025-01-10 00:31:40,631 - optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 1e-05
    maximize: False
    weight_decay: 0.0001
)
2025-01-10 00:31:40,631 - loss:      CrossEntropyLoss()
2025-01-10 00:31:40,631 - epochs:    50
2025-01-10 00:31:40,631 - name:      weights_1

2025-01-10 00:47:34,686 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-10 00:47:34,687 - 0        0.396686   0.517069   0.464934   0.023964   0.892199   1.0e-04 , 1.0e-05 
2025-01-10 01:03:29,955 - 1        0.284140   0.423529   0.504457   0.105264   0.914366   1.0e-04 , 1.0e-05 
2025-01-10 01:03:29,956 - > saved mIoU
2025-01-10 01:19:27,018 - 2        0.223840   0.398705   0.528932   0.141940   0.921049   1.0e-04 , 1.0e-05 
2025-01-10 01:19:27,018 - > saved mIoU
2025-01-10 01:35:22,626 - 3        0.184709   0.389110   0.532183   0.165245   0.921445   1.0e-04 , 1.0e-05 
2025-01-10 01:35:22,627 - > saved mIoU
2025-01-10 01:51:18,842 - 4        0.160421   0.384248   0.549551   0.197824   0.926855   1.0e-04 , 1.0e-05 
2025-01-10 01:51:18,843 - > saved mIoU
2025-01-10 02:07:15,137 - 5        0.144900   0.386854   0.554898   0.218048   0.925811   1.0e-04 , 1.0e-05 
2025-01-10 02:07:15,138 - > saved mIoU
2025-01-10 02:23:09,544 - 6        0.131761   0.409368   0.561849   0.246573   0.927975   1.0e-04 , 1.0e-05 
2025-01-10 02:23:09,544 - > saved mIoU
2025-01-10 02:39:04,869 - 7        0.125627   0.379319   0.567387   0.244796   0.928908   1.0e-04 , 1.0e-05 
2025-01-10 02:39:04,870 - > saved mIoU
2025-01-10 02:55:01,258 - 8        0.118705   0.394847   0.566273   0.231488   0.926917   1.0e-04 , 1.0e-05 
2025-01-10 03:10:56,506 - 9        0.111056   0.375985   0.585765   0.262834   0.934254   1.0e-04 , 1.0e-05 
2025-01-10 03:10:56,506 - > saved mIoU
2025-01-10 03:26:51,870 - 10       0.109766   0.399814   0.576099   0.199487   0.931357   1.0e-04 , 1.0e-05 
2025-01-10 03:42:46,343 - 11       0.108510   0.372279   0.588296   0.282101   0.928666   1.0e-04 , 1.0e-05 
2025-01-10 03:42:46,344 - > saved mIoU
2025-01-10 03:58:42,334 - 12       0.101140   0.381575   0.594623   0.284599   0.934828   1.0e-04 , 1.0e-05 
2025-01-10 03:58:42,334 - > saved mIoU
2025-01-10 04:14:38,407 - 13       0.096927   0.370235   0.597835   0.260720   0.935687   1.0e-04 , 1.0e-05 
2025-01-10 04:14:38,408 - > saved mIoU
2025-01-10 04:30:34,946 - 14       0.094681   0.378972   0.602510   0.257822   0.938478   1.0e-04 , 1.0e-05 
2025-01-10 04:30:34,946 - > saved mIoU
2025-01-10 04:46:31,478 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-10 04:46:31,479 - 15       0.095517   0.389667   0.562402   0.169302   0.922688   1.0e-04 , 1.0e-05 
2025-01-10 05:02:26,222 - 16       0.090797   0.368081   0.598257   0.276291   0.936480   1.0e-04 , 1.0e-05 
2025-01-10 05:18:22,295 - 17       0.086733   0.346267   0.618553   0.328297   0.937781   1.0e-04 , 1.0e-05 
2025-01-10 05:18:22,295 - > saved mIoU
2025-01-10 05:34:19,067 - 18       0.084935   0.373260   0.616396   0.311793   0.934403   1.0e-04 , 1.0e-05 
2025-01-10 05:50:14,037 - 19       0.084935   0.360576   0.608805   0.308992   0.940854   1.0e-04 , 1.0e-05 
2025-01-10 06:06:08,582 - 20       0.082976   0.376204   0.618267   0.328380   0.937145   1.0e-04 , 1.0e-05 
2025-01-10 06:22:03,817 - 21       0.080188   0.381103   0.614883   0.324007   0.930953   1.0e-04 , 1.0e-05 
2025-01-10 06:38:00,229 - 22       0.080902   0.381550   0.606153   0.326611   0.935088   1.0e-04 , 1.0e-05 
2025-01-10 06:53:55,878 - 23       0.082671   0.405719   0.613249   0.296429   0.936172   1.0e-04 , 1.0e-05 
2025-01-10 07:09:52,213 - 24       0.078846   0.366794   0.629370   0.318916   0.938607   1.0e-04 , 1.0e-05 
2025-01-10 07:09:52,213 - > saved mIoU
2025-01-10 07:25:48,637 - 25       0.076803   0.374410   0.623405   0.306106   0.942098   1.0e-04 , 1.0e-05 
2025-01-10 07:41:43,909 - 26       0.074958   0.383312   0.624089   0.317289   0.943956   5.0e-05 , 5.0e-06 
2025-01-10 07:57:40,639 - 27       0.071763   0.394109   0.628666   0.332854   0.944815   5.0e-05 , 5.0e-06 
2025-01-10 08:13:36,001 - 28       0.069918   0.376303   0.643262   0.349783   0.939997   5.0e-05 , 5.0e-06 
2025-01-10 08:13:36,001 - > saved mIoU
2025-01-10 08:29:33,222 - 29       0.068653   0.386924   0.627989   0.328169   0.941016   5.0e-05 , 5.0e-06 
2025-01-10 08:45:27,406 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-10 08:45:27,406 - 30       0.067022   0.376772   0.639156   0.350230   0.942000   5.0e-05 , 5.0e-06 
2025-01-10 09:01:19,895 - 31       0.066719   0.386161   0.633390   0.338357   0.941610   5.0e-05 , 5.0e-06 
2025-01-10 09:17:12,542 - 32       0.067420   0.399029   0.625643   0.333163   0.942122   5.0e-05 , 5.0e-06 
2025-01-10 09:33:05,486 - 33       0.065657   0.424562   0.613835   0.315570   0.943166   5.0e-05 , 5.0e-06 
2025-01-10 09:48:55,461 - 34       0.065857   0.380492   0.644298   0.338158   0.944277   2.5e-05 , 2.5e-06 
2025-01-10 09:48:55,462 - > saved mIoU
2025-01-10 10:04:48,275 - 35       0.063775   0.390868   0.636591   0.345110   0.941282   2.5e-05 , 2.5e-06 
2025-01-10 10:20:37,661 - 36       0.063064   0.389594   0.640968   0.352654   0.943909   2.5e-05 , 2.5e-06 
2025-01-10 10:36:27,683 - 37       0.062103   0.392594   0.639902   0.360147   0.941042   2.5e-05 , 2.5e-06 
2025-01-10 10:52:16,503 - 38       0.062149   0.416437   0.627940   0.340601   0.940812   2.5e-05 , 2.5e-06 
2025-01-10 11:08:06,121 - 39       0.062563   0.388446   0.628156   0.358342   0.939018   2.5e-05 , 2.5e-06 
2025-01-10 11:23:54,813 - 40       0.061306   0.386758   0.629695   0.347031   0.940512   2.5e-05 , 2.5e-06 
2025-01-10 11:39:43,612 - 41       0.060801   0.377324   0.634786   0.329413   0.937184   2.5e-05 , 2.5e-06 
2025-01-10 11:55:32,630 - 42       0.060863   0.393623   0.631967   0.329931   0.942372   1.3e-05 , 1.3e-06 
2025-01-10 12:11:21,350 - 43       0.060478   0.386177   0.636361   0.348729   0.943300   1.3e-05 , 1.3e-06 
2025-01-10 12:27:10,522 - 44       0.060197   0.400460   0.632680   0.348898   0.943064   1.3e-05 , 1.3e-06 
2025-01-10 12:42:59,155 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-10 12:42:59,156 - 45       0.059324   0.406265   0.632919   0.343142   0.942552   1.3e-05 , 1.3e-06 
2025-01-10 12:58:47,160 - 46       0.058904   0.400882   0.635609   0.351602   0.944060   1.3e-05 , 1.3e-06 
2025-01-10 13:14:33,800 - 47       0.058575   0.392419   0.634792   0.337643   0.944579   1.3e-05 , 1.3e-06 
2025-01-10 13:30:20,130 - 48       0.058245   0.394630   0.640028   0.353141   0.944579   1.3e-05 , 1.3e-06 
2025-01-10 13:46:05,399 - 49       0.058065   0.409441   0.633027   0.356680   0.943950   1.3e-05 , 1.3e-06 
2025-01-10 13:46:05,400 - Fine del training

