2025-01-10 21:33:23,063 - device          : cuda:3
2025-01-10 21:33:23,063 - model           : resnet101
2025-01-10 21:33:23,064 - mlp             : 0
2025-01-10 21:33:23,064 - vae             : False
2025-01-10 21:33:23,064 - epochs          : 50
2025-01-10 21:33:23,064 - batch           : 16
2025-01-10 21:33:23,064 - lr              : 0.0001
2025-01-10 21:33:23,064 - crop            : 512
2025-01-10 21:33:23,064 - optimizer       : adam
2025-01-10 21:33:23,064 - biases          : False
2025-01-10 21:33:23,064 - focal_loss      : 0
2025-01-10 21:33:23,064 - activation      : softmax
2025-01-10 21:33:23,064 - class_weights   : False
2025-01-10 21:33:23,064 - norm_weights    : False
2025-01-10 21:33:23,064 - p               : 0.3
2025-01-10 21:33:23,064 - entropy         : 1.0
2025-01-10 21:33:23,072 - Dataset Creati
2025-01-10 21:33:23,072 - Training images: 5125
2025-01-10 21:33:23,073 - Validation images: 1031

2025-01-10 21:33:23,073 - Dataloader Creati
2025-01-10 21:33:23,073 - Training batches: 320
2025-01-10 21:33:23,073 - Validation batches: 128

2025-01-10 21:33:26,871 - Model: deeplabv3plus_resnet101

2025-01-10 21:33:26,941 - Modello caricato correttamente su cuda:3

2025-01-10 21:33:26,945 - Inizio del training
2025-01-10 21:33:26,945 - optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 1e-05
    maximize: False
    weight_decay: 0.0001
)
2025-01-10 21:33:26,945 - loss:      CE_EntropyMinimization(
  (ce_loss): CrossEntropyLoss()
)
2025-01-10 21:33:26,945 - epochs:    15
2025-01-10 21:33:26,945 - name:      weights_0

2025-01-10 21:39:49,911 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-10 21:39:49,912 - 0        2.145226   1.397144   0.224537   0.000000   0.772238   1.0e-04 , 1.0e-05 
2025-01-10 21:46:11,414 - 1        1.416273   1.230538   0.246907   0.000000   0.798293   1.0e-04 , 1.0e-05 
2025-01-10 21:46:11,415 - > saved mIoU
2025-01-10 21:52:32,733 - 2        1.277318   1.136684   0.266455   0.000000   0.809618   1.0e-04 , 1.0e-05 
2025-01-10 21:52:32,733 - > saved mIoU
2025-01-10 21:58:54,054 - 3        1.192046   1.120993   0.274720   0.000000   0.812657   1.0e-04 , 1.0e-05 
2025-01-10 21:58:54,055 - > saved mIoU
2025-01-10 22:05:16,202 - 4        1.160662   1.123808   0.290257   0.000000   0.814634   1.0e-04 , 1.0e-05 
2025-01-10 22:05:16,203 - > saved mIoU
2025-01-10 22:11:39,801 - 5        1.122866   1.144827   0.294828   0.000000   0.809319   1.0e-04 , 1.0e-05 
2025-01-10 22:11:39,802 - > saved mIoU
2025-01-10 22:18:01,891 - 6        1.088213   1.100082   0.303736   0.000000   0.818745   1.0e-04 , 1.0e-05 
2025-01-10 22:18:01,892 - > saved mIoU
2025-01-10 22:24:25,137 - 7        1.060579   1.091946   0.305381   0.000000   0.823389   1.0e-04 , 1.0e-05 
2025-01-10 22:24:25,137 - > saved mIoU
2025-01-10 22:30:48,191 - 8        1.039467   1.074670   0.314878   0.000000   0.826606   1.0e-04 , 1.0e-05 
2025-01-10 22:30:48,191 - > saved mIoU
2025-01-10 22:37:12,000 - 9        1.016882   1.096786   0.313491   0.000000   0.825291   1.0e-04 , 1.0e-05 
2025-01-10 22:43:34,224 - 10       1.003399   1.104658   0.320798   0.000000   0.823865   1.0e-04 , 1.0e-05 
2025-01-10 22:43:34,227 - > saved mIoU
2025-01-10 22:49:57,369 - 11       0.989399   1.127063   0.321367   0.000000   0.818440   1.0e-04 , 1.0e-05 
2025-01-10 22:49:57,369 - > saved mIoU
2025-01-10 22:56:20,700 - 12       0.982869   1.093713   0.327652   0.000000   0.823308   1.0e-04 , 1.0e-05 
2025-01-10 22:56:20,700 - > saved mIoU
2025-01-10 23:02:44,183 - 13       0.956861   1.113049   0.327142   0.000000   0.825957   1.0e-04 , 1.0e-05 
2025-01-10 23:09:06,208 - 14       0.963048   1.131156   0.330219   0.000000   0.821127   1.0e-04 , 1.0e-05 
2025-01-10 23:09:06,209 - > saved mIoU
2025-01-10 23:09:06,703 - Fine del training

2025-01-10 23:09:06,975 - 
Caricati i pesi in: /raid/homespace/piecestola/space/ML4CV/results/train_8/ckpts/weights_mIoU_0.pt

2025-01-10 23:09:06,979 - Inizio del training
2025-01-10 23:09:06,979 - optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 5e-05
    maximize: False
    weight_decay: 0.0001

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 5e-06
    maximize: False
    weight_decay: 0.0001
)
2025-01-10 23:09:06,979 - loss:      CE_EntropyMinimization(
  (ce_loss): CrossEntropyLoss()
)
2025-01-10 23:09:06,980 - epochs:    50
2025-01-10 23:09:06,980 - name:      weights_1

2025-01-10 23:25:02,862 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-10 23:25:02,863 - 0        0.765256   0.817928   0.392922   0.000000   0.882332   5.0e-05 , 5.0e-06 
2025-01-10 23:41:00,197 - 1        0.568843   0.728698   0.429025   0.000000   0.904230   5.0e-05 , 5.0e-06 
2025-01-10 23:41:00,198 - > saved mIoU
2025-01-10 23:56:56,775 - 2        0.478127   0.720735   0.448812   0.000000   0.900832   5.0e-05 , 5.0e-06 
2025-01-10 23:56:56,775 - > saved mIoU
2025-01-11 00:12:53,173 - 3        0.413056   0.688788   0.466793   0.000000   0.909167   5.0e-05 , 5.0e-06 
2025-01-11 00:12:53,174 - > saved mIoU
2025-01-11 00:28:50,631 - 4        0.365047   0.660874   0.473004   0.000148   0.910821   5.0e-05 , 5.0e-06 
2025-01-11 00:28:50,631 - > saved mIoU
2025-01-11 00:44:48,808 - 5        0.335074   0.689561   0.483244   0.003786   0.915951   5.0e-05 , 5.0e-06 
2025-01-11 00:44:48,809 - > saved mIoU
2025-01-11 01:00:46,683 - 6        0.308102   0.665597   0.502076   0.139454   0.916273   5.0e-05 , 5.0e-06 
2025-01-11 01:00:46,684 - > saved mIoU
2025-01-11 01:16:44,713 - 7        0.289767   0.667934   0.506994   0.189175   0.919745   5.0e-05 , 5.0e-06 
2025-01-11 01:16:44,713 - > saved mIoU
2025-01-11 01:32:43,587 - 8        0.275469   0.645855   0.517723   0.186166   0.920072   5.0e-05 , 5.0e-06 
2025-01-11 01:32:43,587 - > saved mIoU
2025-01-11 01:48:41,991 - 9        0.254440   0.646213   0.537674   0.215583   0.924343   5.0e-05 , 5.0e-06 
2025-01-11 01:48:41,991 - > saved mIoU
2025-01-11 02:04:40,853 - 10       0.241867   0.627777   0.548118   0.223098   0.927588   5.0e-05 , 5.0e-06 
2025-01-11 02:04:40,854 - > saved mIoU
2025-01-11 02:20:40,091 - 11       0.231700   0.617528   0.559048   0.237432   0.926288   5.0e-05 , 5.0e-06 
2025-01-11 02:20:40,092 - > saved mIoU
2025-01-11 02:36:38,224 - 12       0.221545   0.644532   0.552780   0.226341   0.924951   5.0e-05 , 5.0e-06 
2025-01-11 02:52:36,533 - 13       0.213314   0.609381   0.572640   0.248455   0.927423   5.0e-05 , 5.0e-06 
2025-01-11 02:52:36,533 - > saved mIoU
2025-01-11 03:08:35,330 - 14       0.207137   0.601210   0.577202   0.256530   0.926896   5.0e-05 , 5.0e-06 
2025-01-11 03:08:35,331 - > saved mIoU
2025-01-11 03:24:35,014 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-11 03:24:35,014 - 15       0.203460   0.595680   0.572531   0.247990   0.928426   5.0e-05 , 5.0e-06 
2025-01-11 03:40:32,258 - 16       0.197793   0.596033   0.583226   0.260686   0.927278   5.0e-05 , 5.0e-06 
2025-01-11 03:40:32,258 - > saved mIoU
2025-01-11 03:56:31,864 - 17       0.190987   0.576790   0.581065   0.262215   0.924532   5.0e-05 , 5.0e-06 
2025-01-11 04:12:26,797 - 18       0.185386   0.604863   0.589741   0.275252   0.923823   5.0e-05 , 5.0e-06 
2025-01-11 04:12:26,797 - > saved mIoU
2025-01-11 04:28:24,637 - 19       0.180317   0.583494   0.593365   0.262308   0.923728   5.0e-05 , 5.0e-06 
2025-01-11 04:28:24,638 - > saved mIoU
2025-01-11 04:44:22,340 - 20       0.177338   0.603812   0.592192   0.273697   0.924320   5.0e-05 , 5.0e-06 
2025-01-11 05:00:18,724 - 21       0.171346   0.571403   0.600834   0.282744   0.933136   5.0e-05 , 5.0e-06 
2025-01-11 05:00:18,725 - > saved mIoU
2025-01-11 05:16:16,337 - 22       0.169791   0.620630   0.589054   0.292124   0.927283   5.0e-05 , 5.0e-06 
2025-01-11 05:32:13,591 - 23       0.165829   0.564969   0.606460   0.292350   0.932098   5.0e-05 , 5.0e-06 
2025-01-11 05:32:13,591 - > saved mIoU
2025-01-11 05:48:11,454 - 24       0.161380   0.610430   0.588362   0.279011   0.927894   5.0e-05 , 5.0e-06 
2025-01-11 06:04:08,417 - 25       0.160281   0.574136   0.606003   0.304654   0.931882   5.0e-05 , 5.0e-06 
2025-01-11 06:20:04,735 - 26       0.155500   0.596602   0.599389   0.306075   0.930913   5.0e-05 , 5.0e-06 
2025-01-11 06:36:02,240 - 27       0.152029   0.590178   0.594366   0.315116   0.933491   5.0e-05 , 5.0e-06 
2025-01-11 06:51:58,268 - 28       0.151331   0.557263   0.610281   0.323235   0.930903   5.0e-05 , 5.0e-06 
2025-01-11 06:51:58,268 - > saved mIoU
2025-01-11 07:07:57,127 - 29       0.152059   0.562011   0.609978   0.325940   0.933516   5.0e-05 , 5.0e-06 
2025-01-11 07:23:54,009 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-11 07:23:54,010 - 30       0.146322   0.561422   0.616564   0.331085   0.926001   5.0e-05 , 5.0e-06 
2025-01-11 07:23:54,010 - > saved mIoU
2025-01-11 07:39:55,174 - 31       0.144469   0.556029   0.605341   0.302303   0.926543   5.0e-05 , 5.0e-06 
2025-01-11 07:55:53,194 - 32       0.145268   0.562954   0.603417   0.308630   0.920307   5.0e-05 , 5.0e-06 
2025-01-11 08:11:52,142 - 33       0.141135   0.548035   0.611410   0.287757   0.930425   5.0e-05 , 5.0e-06 
2025-01-11 08:27:48,982 - 34       0.144019   0.583999   0.592517   0.294379   0.930069   5.0e-05 , 5.0e-06 
2025-01-11 08:43:46,049 - 35       0.141234   0.610287   0.604364   0.262022   0.925471   5.0e-05 , 5.0e-06 
2025-01-11 08:59:43,767 - 36       0.138449   0.600524   0.601547   0.308844   0.923820   5.0e-05 , 5.0e-06 
2025-01-11 09:15:40,998 - 37       0.135298   0.602342   0.605775   0.286040   0.929727   5.0e-05 , 5.0e-06 
2025-01-11 09:31:38,533 - 38       0.135883   0.666559   0.586258   0.256069   0.925683   5.0e-05 , 5.0e-06 
2025-01-11 09:47:36,250 - 39       0.136963   0.573894   0.613808   0.294508   0.933163   5.0e-05 , 5.0e-06 
2025-01-11 10:03:34,330 - 40       0.134147   0.567957   0.622702   0.337998   0.938417   2.5e-05 , 2.5e-06 
2025-01-11 10:03:34,331 - > saved mIoU
2025-01-11 10:19:32,427 - 41       0.130329   0.560412   0.626923   0.337003   0.936214   2.5e-05 , 2.5e-06 
2025-01-11 10:19:32,428 - > saved mIoU
2025-01-11 10:35:31,289 - 42       0.126643   0.592119   0.622868   0.342686   0.931099   2.5e-05 , 2.5e-06 
2025-01-11 10:51:29,680 - 43       0.124838   0.574825   0.619355   0.339140   0.930825   2.5e-05 , 2.5e-06 
2025-01-11 11:07:27,057 - 44       0.123698   0.601031   0.621470   0.352605   0.932027   2.5e-05 , 2.5e-06 
2025-01-11 11:23:26,111 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-11 11:23:26,111 - 45       0.122621   0.616823   0.612010   0.315656   0.930507   2.5e-05 , 2.5e-06 
2025-01-11 11:39:23,092 - 46       0.121873   0.601991   0.615386   0.346943   0.931698   1.3e-05 , 1.3e-06 
2025-01-11 11:55:20,400 - 47       0.120318   0.592081   0.618575   0.341313   0.931794   1.3e-05 , 1.3e-06 
2025-01-11 12:11:19,294 - 48       0.119195   0.603359   0.613791   0.335247   0.931350   1.3e-05 , 1.3e-06 
2025-01-11 12:27:18,675 - 49       0.118248   0.616641   0.610584   0.338523   0.931591   1.3e-05 , 1.3e-06 
2025-01-11 12:27:18,676 - Fine del training

