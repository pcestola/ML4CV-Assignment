2025-01-09 22:54:10,483 - device          : cuda:1
2025-01-09 22:54:10,484 - model           : resnet101
2025-01-09 22:54:10,484 - mlp             : 0
2025-01-09 22:54:10,484 - vae             : False
2025-01-09 22:54:10,484 - epochs          : 50
2025-01-09 22:54:10,484 - batch           : 16
2025-01-09 22:54:10,484 - lr              : 0.0001
2025-01-09 22:54:10,484 - crop            : 512
2025-01-09 22:54:10,484 - optimizer       : adam
2025-01-09 22:54:10,484 - biases          : False
2025-01-09 22:54:10,484 - focal_loss      : 0
2025-01-09 22:54:10,484 - activation      : softmax
2025-01-09 22:54:10,484 - class_weights   : False
2025-01-09 22:54:10,484 - norm_weights    : False
2025-01-09 22:54:10,484 - p               : 0.3
2025-01-09 22:54:10,493 - Dataset Creati
2025-01-09 22:54:10,493 - Training images: 5125
2025-01-09 22:54:10,493 - Validation images: 1031

2025-01-09 22:54:10,494 - Dataloader Creati
2025-01-09 22:54:10,494 - Training batches: 320
2025-01-09 22:54:10,494 - Validation batches: 128

2025-01-09 22:54:14,344 - Model: deeplabv3plus_resnet101

2025-01-09 22:54:14,410 - Modello caricato correttamente su cuda:1

2025-01-09 22:54:14,413 - Inizio del training
2025-01-09 22:54:14,413 - optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 1e-05
    maximize: False
    weight_decay: 0.0001
)
2025-01-09 22:54:14,413 - loss:      CrossEntropyLoss()
2025-01-09 22:54:14,413 - epochs:    15
2025-01-09 22:54:14,413 - name:      weights_0

2025-01-09 23:00:05,549 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-09 23:00:05,549 - 0        1.155035   0.714357   0.296477   0.000000   0.806712   1.0e-04 , 1.0e-05 
2025-01-09 23:06:06,283 - 1        0.875762   0.685579   0.317652   0.000000   0.803987   1.0e-04 , 1.0e-05 
2025-01-09 23:06:06,283 - > saved mIoU
2025-01-09 23:12:10,316 - 2        0.800805   0.672030   0.329052   0.000000   0.802267   1.0e-04 , 1.0e-05 
2025-01-09 23:12:10,317 - > saved mIoU
2025-01-09 23:18:08,344 - 3        0.764644   0.657647   0.339762   0.022182   0.811680   1.0e-04 , 1.0e-05 
2025-01-09 23:18:08,344 - > saved mIoU
2025-01-09 23:24:03,798 - 4        0.738396   0.631072   0.352680   0.028503   0.817522   1.0e-04 , 1.0e-05 
2025-01-09 23:24:03,799 - > saved mIoU
2025-01-09 23:30:02,329 - 5        0.718426   0.673428   0.369619   0.032703   0.796407   1.0e-04 , 1.0e-05 
2025-01-09 23:30:02,330 - > saved mIoU
2025-01-09 23:36:03,220 - 6        0.695478   0.652544   0.382050   0.032016   0.812798   1.0e-04 , 1.0e-05 
2025-01-09 23:36:03,220 - > saved mIoU
2025-01-09 23:41:59,033 - 7        0.682194   0.686453   0.381028   0.037107   0.792114   1.0e-04 , 1.0e-05 
2025-01-09 23:47:59,411 - 8        0.661530   0.677494   0.387784   0.035673   0.798024   1.0e-04 , 1.0e-05 
2025-01-09 23:47:59,411 - > saved mIoU
2025-01-09 23:53:57,898 - 9        0.656740   0.634659   0.394671   0.038976   0.818213   1.0e-04 , 1.0e-05 
2025-01-09 23:53:57,899 - > saved mIoU
2025-01-10 00:00:00,549 - 10       0.646402   0.656907   0.397180   0.044703   0.809431   1.0e-04 , 1.0e-05 
2025-01-10 00:00:00,549 - > saved mIoU
2025-01-10 00:06:00,720 - 11       0.633831   0.630287   0.403439   0.060621   0.823094   5.0e-05 , 5.0e-06 
2025-01-10 00:06:00,721 - > saved mIoU
2025-01-10 00:11:56,435 - 12       0.623687   0.659890   0.399628   0.064159   0.810863   5.0e-05 , 5.0e-06 
2025-01-10 00:17:52,674 - 13       0.619459   0.641226   0.405985   0.063313   0.819824   5.0e-05 , 5.0e-06 
2025-01-10 00:17:52,674 - > saved mIoU
2025-01-10 00:23:42,856 - 14       0.609013   0.648905   0.404803   0.062998   0.816426   5.0e-05 , 5.0e-06 
2025-01-10 00:23:42,857 - Fine del training

2025-01-10 00:23:43,133 - 
Caricati i pesi in: /raid/homespace/piecestola/space/ML4CV/results/train_2/ckpts/weights_mIoU_0.pt

2025-01-10 00:23:43,134 - Inizio del training
2025-01-10 00:23:43,134 - optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 5e-05
    maximize: False
    weight_decay: 0.0001

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 5e-06
    maximize: False
    weight_decay: 0.0001
)
2025-01-10 00:23:43,134 - loss:      CrossEntropyLoss()
2025-01-10 00:23:43,134 - epochs:    50
2025-01-10 00:23:43,134 - name:      weights_1

2025-01-10 00:35:22,599 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-10 00:35:22,599 - 0        0.548108   0.510600   0.452061   0.081062   0.885546   5.0e-05 , 5.0e-06 
2025-01-10 00:47:00,750 - 1        0.405265   0.444005   0.483638   0.129725   0.898298   5.0e-05 , 5.0e-06 
2025-01-10 00:47:00,751 - > saved mIoU
2025-01-10 00:58:37,865 - 2        0.341836   0.425660   0.500625   0.162023   0.906047   5.0e-05 , 5.0e-06 
2025-01-10 00:58:37,866 - > saved mIoU
2025-01-10 01:10:19,950 - 3        0.291413   0.414317   0.513499   0.167246   0.914494   5.0e-05 , 5.0e-06 
2025-01-10 01:10:19,950 - > saved mIoU
2025-01-10 01:21:58,434 - 4        0.254125   0.399691   0.531561   0.183301   0.917271   5.0e-05 , 5.0e-06 
2025-01-10 01:21:58,434 - > saved mIoU
2025-01-10 01:33:37,442 - 5        0.232351   0.397493   0.540233   0.183496   0.921768   5.0e-05 , 5.0e-06 
2025-01-10 01:33:37,442 - > saved mIoU
2025-01-10 01:45:16,897 - 6        0.218546   0.388044   0.544171   0.202176   0.923780   5.0e-05 , 5.0e-06 
2025-01-10 01:45:16,898 - > saved mIoU
2025-01-10 01:56:57,349 - 7        0.199129   0.382071   0.555736   0.192610   0.922770   5.0e-05 , 5.0e-06 
2025-01-10 01:56:57,350 - > saved mIoU
2025-01-10 02:08:35,123 - 8        0.184309   0.387352   0.559217   0.214862   0.923774   5.0e-05 , 5.0e-06 
2025-01-10 02:08:35,124 - > saved mIoU
2025-01-10 02:20:12,216 - 9        0.177232   0.381358   0.572842   0.209902   0.919770   5.0e-05 , 5.0e-06 
2025-01-10 02:20:12,216 - > saved mIoU
2025-01-10 02:31:51,320 - 10       0.165384   0.364909   0.583780   0.229391   0.927378   5.0e-05 , 5.0e-06 
2025-01-10 02:31:51,321 - > saved mIoU
2025-01-10 02:43:33,361 - 11       0.158305   0.368105   0.586812   0.234758   0.927890   5.0e-05 , 5.0e-06 
2025-01-10 02:43:33,361 - > saved mIoU
2025-01-10 02:55:12,864 - 12       0.151492   0.367177   0.576806   0.231355   0.924000   5.0e-05 , 5.0e-06 
2025-01-10 03:06:51,997 - 13       0.144050   0.370077   0.589966   0.244557   0.932073   5.0e-05 , 5.0e-06 
2025-01-10 03:06:51,997 - > saved mIoU
2025-01-10 03:18:34,497 - 14       0.138768   0.379941   0.576672   0.233115   0.932440   5.0e-05 , 5.0e-06 
2025-01-10 03:30:12,822 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-10 03:30:12,823 - 15       0.136478   0.374398   0.596775   0.250230   0.923968   5.0e-05 , 5.0e-06 
2025-01-10 03:30:12,823 - > saved mIoU
2025-01-10 03:41:53,148 - 16       0.136971   0.358828   0.593423   0.263233   0.931207   5.0e-05 , 5.0e-06 
2025-01-10 03:53:32,427 - 17       0.131403   0.354146   0.600241   0.243165   0.934754   5.0e-05 , 5.0e-06 
2025-01-10 03:53:32,427 - > saved mIoU
2025-01-10 04:05:12,191 - 18       0.126236   0.351005   0.605113   0.260726   0.931794   5.0e-05 , 5.0e-06 
2025-01-10 04:05:12,192 - > saved mIoU
2025-01-10 04:16:50,648 - 19       0.123176   0.370375   0.590890   0.253642   0.932558   5.0e-05 , 5.0e-06 
2025-01-10 04:28:29,339 - 20       0.119575   0.367987   0.595050   0.274102   0.929775   5.0e-05 , 5.0e-06 
2025-01-10 04:40:08,066 - 21       0.117688   0.341595   0.606464   0.259304   0.935466   5.0e-05 , 5.0e-06 
2025-01-10 04:40:08,067 - > saved mIoU
2025-01-10 04:51:48,556 - 22       0.116866   0.334527   0.612558   0.279140   0.937152   5.0e-05 , 5.0e-06 
2025-01-10 04:51:48,556 - > saved mIoU
2025-01-10 05:03:30,016 - 23       0.113852   0.346144   0.612657   0.256716   0.934125   5.0e-05 , 5.0e-06 
2025-01-10 05:03:30,017 - > saved mIoU
2025-01-10 05:15:10,403 - 24       0.112389   0.371978   0.601531   0.275716   0.936837   5.0e-05 , 5.0e-06 
2025-01-10 05:26:49,966 - 25       0.109668   0.376237   0.591093   0.281894   0.933127   5.0e-05 , 5.0e-06 
2025-01-10 05:38:29,663 - 26       0.107703   0.343946   0.609885   0.303697   0.934900   5.0e-05 , 5.0e-06 
2025-01-10 05:50:07,905 - 27       0.105414   0.372319   0.600323   0.289742   0.931332   5.0e-05 , 5.0e-06 
2025-01-10 06:01:46,359 - 28       0.104629   0.374094   0.605200   0.301703   0.938533   5.0e-05 , 5.0e-06 
2025-01-10 06:13:24,180 - 29       0.101961   0.351475   0.621287   0.288308   0.933270   2.5e-05 , 2.5e-06 
2025-01-10 06:13:24,180 - > saved mIoU
2025-01-10 06:25:05,153 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-10 06:25:05,154 - 30       0.098197   0.351560   0.593639   0.256586   0.922295   2.5e-05 , 2.5e-06 
2025-01-10 06:36:44,883 - 31       0.094972   0.360265   0.608068   0.286454   0.930400   2.5e-05 , 2.5e-06 
2025-01-10 06:48:24,906 - 32       0.093455   0.353950   0.612225   0.290968   0.937153   2.5e-05 , 2.5e-06 
2025-01-10 07:00:04,843 - 33       0.093098   0.371370   0.606264   0.304572   0.937089   2.5e-05 , 2.5e-06 
2025-01-10 07:11:42,944 - 34       0.092468   0.367936   0.621114   0.315035   0.939990   2.5e-05 , 2.5e-06 
2025-01-10 07:23:22,244 - 35       0.091248   0.380066   0.616682   0.314700   0.937164   1.3e-05 , 1.3e-06 
2025-01-10 07:35:02,002 - 36       0.089414   0.366255   0.617318   0.307416   0.937324   1.3e-05 , 1.3e-06 
2025-01-10 07:46:43,831 - 37       0.088076   0.371029   0.621537   0.311717   0.938954   1.3e-05 , 1.3e-06 
2025-01-10 07:46:43,832 - > saved mIoU
2025-01-10 07:58:23,573 - 38       0.087183   0.354904   0.622891   0.305423   0.937622   1.3e-05 , 1.3e-06 
2025-01-10 07:58:23,573 - > saved mIoU
2025-01-10 08:10:06,360 - 39       0.086850   0.361129   0.624330   0.317958   0.938767   1.3e-05 , 1.3e-06 
2025-01-10 08:10:06,360 - > saved mIoU
2025-01-10 08:21:48,459 - 40       0.086518   0.370560   0.621552   0.309893   0.939916   1.3e-05 , 1.3e-06 
2025-01-10 08:33:27,265 - 41       0.086491   0.362856   0.626372   0.316858   0.938256   6.3e-06 , 6.3e-07 
2025-01-10 08:33:27,265 - > saved mIoU
2025-01-10 08:45:06,782 - 42       0.085660   0.370555   0.619716   0.313369   0.939083   6.3e-06 , 6.3e-07 
2025-01-10 08:56:39,006 - 43       0.085004   0.364139   0.625542   0.318414   0.938823   6.3e-06 , 6.3e-07 
2025-01-10 09:08:11,445 - 44       0.084219   0.366798   0.626122   0.316457   0.937501   6.3e-06 , 6.3e-07 
2025-01-10 09:19:43,376 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-10 09:19:43,376 - 45       0.083352   0.359038   0.627253   0.317783   0.938194   6.3e-06 , 6.3e-07 
2025-01-10 09:19:43,376 - > saved mIoU
2025-01-10 09:31:17,647 - 46       0.083795   0.358534   0.627214   0.316752   0.939231   6.3e-06 , 6.3e-07 
2025-01-10 09:42:51,185 - 47       0.083531   0.368031   0.622856   0.317076   0.940043   3.1e-06 , 3.1e-07 
2025-01-10 09:54:25,399 - 48       0.083349   0.365524   0.625763   0.319727   0.939148   3.1e-06 , 3.1e-07 
2025-01-10 10:05:58,591 - 49       0.082834   0.364820   0.624751   0.320672   0.938848   3.1e-06 , 3.1e-07 
2025-01-10 10:05:58,591 - Fine del training

