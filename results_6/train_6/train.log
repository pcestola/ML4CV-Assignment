2025-01-10 20:28:37,618 - device          : cuda:1
2025-01-10 20:28:37,618 - model           : resnet101
2025-01-10 20:28:37,618 - mlp             : 0
2025-01-10 20:28:37,618 - vae             : False
2025-01-10 20:28:37,618 - epochs          : 50
2025-01-10 20:28:37,618 - batch           : 16
2025-01-10 20:28:37,618 - lr              : 0.0001
2025-01-10 20:28:37,618 - crop            : 512
2025-01-10 20:28:37,618 - optimizer       : adam
2025-01-10 20:28:37,618 - biases          : False
2025-01-10 20:28:37,618 - focal_loss      : 0
2025-01-10 20:28:37,618 - activation      : softmax
2025-01-10 20:28:37,618 - class_weights   : False
2025-01-10 20:28:37,618 - norm_weights    : False
2025-01-10 20:28:37,619 - p               : 0.3
2025-01-10 20:28:37,626 - Dataset Creati
2025-01-10 20:28:37,626 - Training images: 5125
2025-01-10 20:28:37,626 - Validation images: 1031

2025-01-10 20:28:37,627 - Dataloader Creati
2025-01-10 20:28:37,627 - Training batches: 320
2025-01-10 20:28:37,627 - Validation batches: 128

2025-01-10 20:28:41,128 - Model: deeplabv3plus_resnet101

2025-01-10 20:28:41,191 - Modello caricato correttamente su cuda:1

2025-01-10 20:28:41,194 - Inizio del training
2025-01-10 20:28:41,194 - optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 1e-05
    maximize: False
    weight_decay: 0.0001
)
2025-01-10 20:28:41,194 - loss:      CrossEntropyLoss()
2025-01-10 20:28:41,194 - epochs:    15
2025-01-10 20:28:41,195 - name:      weights_0

2025-01-10 20:34:51,937 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-10 20:34:51,937 - 0        1.123199   0.819506   0.263782   0.000000   0.776092   1.0e-04 , 1.0e-05 
2025-01-10 20:41:01,801 - 1        0.790579   0.732915   0.293665   0.000000   0.802890   1.0e-04 , 1.0e-05 
2025-01-10 20:41:01,801 - > saved mIoU
2025-01-10 20:47:13,445 - 2        0.717304   0.686283   0.308195   0.000000   0.811709   1.0e-04 , 1.0e-05 
2025-01-10 20:47:13,445 - > saved mIoU
2025-01-10 20:53:23,755 - 3        0.670647   0.676339   0.312241   0.000000   0.815214   1.0e-04 , 1.0e-05 
2025-01-10 20:53:23,755 - > saved mIoU
2025-01-10 20:59:33,955 - 4        0.652712   0.682948   0.321057   0.000000   0.813592   1.0e-04 , 1.0e-05 
2025-01-10 20:59:33,955 - > saved mIoU
2025-01-10 21:05:44,178 - 5        0.632524   0.702684   0.321431   0.000000   0.800484   1.0e-04 , 1.0e-05 
2025-01-10 21:05:44,178 - > saved mIoU
2025-01-10 21:11:56,557 - 6        0.612186   0.671911   0.331103   0.000000   0.816379   1.0e-04 , 1.0e-05 
2025-01-10 21:11:56,558 - > saved mIoU
2025-01-10 21:18:08,759 - 7        0.595708   0.668409   0.332956   0.000000   0.821703   1.0e-04 , 1.0e-05 
2025-01-10 21:18:08,760 - > saved mIoU
2025-01-10 21:24:19,443 - 8        0.584426   0.658999   0.341338   0.000000   0.822462   1.0e-04 , 1.0e-05 
2025-01-10 21:24:19,443 - > saved mIoU
2025-01-10 21:30:31,072 - 9        0.571556   0.670948   0.340228   0.000000   0.824320   1.0e-04 , 1.0e-05 
2025-01-10 21:36:43,820 - 10       0.564063   0.681446   0.347067   0.000000   0.816366   1.0e-04 , 1.0e-05 
2025-01-10 21:36:43,821 - > saved mIoU
2025-01-10 21:43:00,061 - 11       0.555901   0.689371   0.348520   0.000000   0.814902   1.0e-04 , 1.0e-05 
2025-01-10 21:43:00,062 - > saved mIoU
2025-01-10 21:49:16,370 - 12       0.552189   0.677034   0.352222   0.000000   0.814384   1.0e-04 , 1.0e-05 
2025-01-10 21:49:16,371 - > saved mIoU
2025-01-10 21:55:32,785 - 13       0.536831   0.679369   0.352020   0.007325   0.822786   1.0e-04 , 1.0e-05 
2025-01-10 22:01:49,051 - 14       0.541070   0.694771   0.352786   0.010239   0.814311   1.0e-04 , 1.0e-05 
2025-01-10 22:01:49,051 - > saved mIoU
2025-01-10 22:01:49,566 - Fine del training

2025-01-10 22:01:49,829 - 
Caricati i pesi in: /raid/homespace/piecestola/space/ML4CV/results/train_6/ckpts/weights_mIoU_0.pt

2025-01-10 22:01:49,830 - Inizio del training
2025-01-10 22:01:49,831 - optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 5e-05
    maximize: False
    weight_decay: 0.0001

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 5e-06
    maximize: False
    weight_decay: 0.0001
)
2025-01-10 22:01:49,831 - loss:      CrossEntropyLoss()
2025-01-10 22:01:49,831 - epochs:    50
2025-01-10 22:01:49,831 - name:      weights_1

2025-01-10 22:17:49,227 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-10 22:17:49,227 - 0        0.439981   0.498515   0.413604   0.000000   0.876462   5.0e-05 , 5.0e-06 
2025-01-10 22:33:48,842 - 1        0.328854   0.452459   0.440188   0.004478   0.902626   5.0e-05 , 5.0e-06 
2025-01-10 22:33:48,843 - > saved mIoU
2025-01-10 22:49:49,034 - 2        0.275037   0.440484   0.461432   0.072299   0.899812   5.0e-05 , 5.0e-06 
2025-01-10 22:49:49,034 - > saved mIoU
2025-01-10 23:05:49,478 - 3        0.237802   0.427141   0.490840   0.147063   0.906433   5.0e-05 , 5.0e-06 
2025-01-10 23:05:49,478 - > saved mIoU
2025-01-10 23:21:44,230 - 4        0.211194   0.413405   0.500616   0.156483   0.911493   5.0e-05 , 5.0e-06 
2025-01-10 23:21:44,231 - > saved mIoU
2025-01-10 23:37:39,563 - 5        0.194609   0.427945   0.515751   0.194596   0.914019   5.0e-05 , 5.0e-06 
2025-01-10 23:37:39,564 - > saved mIoU
2025-01-10 23:53:36,308 - 6        0.178853   0.415804   0.529283   0.198520   0.915214   5.0e-05 , 5.0e-06 
2025-01-10 23:53:36,309 - > saved mIoU
2025-01-11 00:09:29,781 - 7        0.168755   0.422876   0.529480   0.196474   0.915950   5.0e-05 , 5.0e-06 
2025-01-11 00:09:29,782 - > saved mIoU
2025-01-11 00:25:25,377 - 8        0.160901   0.415947   0.534669   0.200649   0.917267   5.0e-05 , 5.0e-06 
2025-01-11 00:25:25,378 - > saved mIoU
2025-01-11 00:41:21,692 - 9        0.148331   0.402506   0.548490   0.229518   0.920910   5.0e-05 , 5.0e-06 
2025-01-11 00:41:21,692 - > saved mIoU
2025-01-11 00:57:17,013 - 10       0.140817   0.396829   0.552942   0.232038   0.925464   5.0e-05 , 5.0e-06 
2025-01-11 00:57:17,014 - > saved mIoU
2025-01-11 01:13:12,440 - 11       0.134912   0.383671   0.562412   0.255604   0.925593   5.0e-05 , 5.0e-06 
2025-01-11 01:13:12,441 - > saved mIoU
2025-01-11 01:29:07,313 - 12       0.128907   0.404370   0.553931   0.240656   0.923906   5.0e-05 , 5.0e-06 
2025-01-11 01:45:00,703 - 13       0.124204   0.389129   0.569992   0.257383   0.928031   5.0e-05 , 5.0e-06 
2025-01-11 01:45:00,703 - > saved mIoU
2025-01-11 02:00:57,216 - 14       0.120728   0.380398   0.570152   0.262243   0.926842   5.0e-05 , 5.0e-06 
2025-01-11 02:00:57,216 - > saved mIoU
2025-01-11 02:16:52,832 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-11 02:16:52,833 - 15       0.118847   0.365627   0.573244   0.254181   0.927740   5.0e-05 , 5.0e-06 
2025-01-11 02:16:52,833 - > saved mIoU
2025-01-11 02:32:48,544 - 16       0.115131   0.366063   0.582553   0.261684   0.924444   5.0e-05 , 5.0e-06 
2025-01-11 02:32:48,545 - > saved mIoU
2025-01-11 02:48:45,831 - 17       0.111478   0.345637   0.585500   0.276889   0.923822   5.0e-05 , 5.0e-06 
2025-01-11 02:48:45,831 - > saved mIoU
2025-01-11 03:04:41,724 - 18       0.107745   0.379968   0.586898   0.291652   0.922709   5.0e-05 , 5.0e-06 
2025-01-11 03:04:41,725 - > saved mIoU
2025-01-11 03:20:37,168 - 19       0.106515   0.369084   0.585594   0.270536   0.921947   5.0e-05 , 5.0e-06 
2025-01-11 03:36:31,401 - 20       0.103556   0.380631   0.588838   0.278734   0.920264   5.0e-05 , 5.0e-06 
2025-01-11 03:36:31,402 - > saved mIoU
2025-01-11 03:52:26,000 - 21       0.098882   0.363530   0.599366   0.299600   0.928954   5.0e-05 , 5.0e-06 
2025-01-11 03:52:26,000 - > saved mIoU
2025-01-11 04:08:20,585 - 22       0.097451   0.384068   0.586603   0.304766   0.926937   5.0e-05 , 5.0e-06 
2025-01-11 04:24:14,096 - 23       0.096371   0.348860   0.607227   0.292736   0.928380   5.0e-05 , 5.0e-06 
2025-01-11 04:24:14,096 - > saved mIoU
2025-01-11 04:40:09,561 - 24       0.094442   0.367958   0.600285   0.307782   0.927349   2.5e-05 , 2.5e-06 
2025-01-11 04:56:02,578 - 25       0.092431   0.350266   0.604046   0.300346   0.926437   2.5e-05 , 2.5e-06 
2025-01-11 05:11:55,408 - 26       0.089502   0.370288   0.597359   0.312557   0.926381   2.5e-05 , 2.5e-06 
2025-01-11 05:27:49,474 - 27       0.087671   0.365871   0.601924   0.313450   0.927883   2.5e-05 , 2.5e-06 
2025-01-11 05:43:41,583 - 28       0.086476   0.360757   0.605544   0.311777   0.931168   2.5e-05 , 2.5e-06 
2025-01-11 05:59:34,827 - 29       0.086109   0.370916   0.597711   0.310640   0.928716   2.5e-05 , 2.5e-06 
2025-01-11 06:15:27,120 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-11 06:15:27,120 - 30       0.084954   0.393496   0.600308   0.309008   0.924646   1.3e-05 , 1.3e-06 
2025-01-11 06:31:20,850 - 31       0.083132   0.383528   0.600017   0.318649   0.925709   1.3e-05 , 1.3e-06 
2025-01-11 06:47:14,533 - 32       0.083213   0.379509   0.601782   0.326820   0.926682   1.3e-05 , 1.3e-06 
2025-01-11 07:03:07,865 - 33       0.081031   0.374454   0.600769   0.314742   0.925248   1.3e-05 , 1.3e-06 
2025-01-11 07:19:01,731 - 34       0.081250   0.379529   0.600070   0.313489   0.928241   1.3e-05 , 1.3e-06 
2025-01-11 07:34:53,811 - 35       0.080199   0.369593   0.603774   0.323571   0.925398   1.3e-05 , 1.3e-06 
2025-01-11 07:50:46,345 - 36       0.080192   0.378286   0.600642   0.318345   0.926971   6.3e-06 , 6.3e-07 
2025-01-11 08:06:40,038 - 37       0.078801   0.378402   0.601747   0.319208   0.927579   6.3e-06 , 6.3e-07 
2025-01-11 08:22:33,374 - 38       0.078899   0.381034   0.600572   0.325181   0.929567   6.3e-06 , 6.3e-07 
2025-01-11 08:38:26,917 - 39       0.079495   0.368152   0.603977   0.320539   0.929566   6.3e-06 , 6.3e-07 
2025-01-11 08:54:20,818 - 40       0.077654   0.372893   0.602616   0.330923   0.928714   6.3e-06 , 6.3e-07 
2025-01-11 09:10:16,016 - 41       0.077280   0.369551   0.601039   0.321953   0.928984   6.3e-06 , 6.3e-07 
2025-01-11 09:26:10,853 - 42       0.077129   0.370342   0.602358   0.325605   0.928904   3.1e-06 , 3.1e-07 
2025-01-11 09:42:06,299 - 43       0.076982   0.367622   0.602111   0.325224   0.929434   3.1e-06 , 3.1e-07 
2025-01-11 09:58:00,981 - 44       0.077258   0.368496   0.602497   0.327792   0.928859   3.1e-06 , 3.1e-07 
2025-01-11 10:13:56,965 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-11 10:13:56,965 - 45       0.076936   0.372415   0.601898   0.326722   0.928535   3.1e-06 , 3.1e-07 
2025-01-11 10:29:50,686 - 46       0.076710   0.370502   0.601047   0.325888   0.928695   3.1e-06 , 3.1e-07 
2025-01-11 10:45:45,720 - 47       0.076297   0.367033   0.602514   0.330238   0.926776   3.1e-06 , 3.1e-07 
2025-01-11 11:01:40,830 - 48       0.076292   0.363400   0.603764   0.328867   0.927759   1.6e-06 , 1.6e-07 
2025-01-11 11:17:34,410 - 49       0.075956   0.366248   0.601461   0.330474   0.928223   1.6e-06 , 1.6e-07 
2025-01-11 11:17:34,411 - Fine del training

