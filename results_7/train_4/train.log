2025-01-14 00:13:22,857 - device          : cuda:4
2025-01-14 00:13:22,857 - model           : mobilenet
2025-01-14 00:13:22,857 - mlp             : 0
2025-01-14 00:13:22,857 - vae             : False
2025-01-14 00:13:22,858 - epochs          : 50
2025-01-14 00:13:22,858 - batch           : 16
2025-01-14 00:13:22,858 - lr              : 0.0001
2025-01-14 00:13:22,858 - crop            : 512
2025-01-14 00:13:22,858 - optimizer       : adam
2025-01-14 00:13:22,858 - biases          : False
2025-01-14 00:13:22,858 - focal_loss      : 0
2025-01-14 00:13:22,858 - activation      : softmax
2025-01-14 00:13:22,858 - class_weights   : False
2025-01-14 00:13:22,858 - norm_weights    : False
2025-01-14 00:13:22,858 - p               : 0.3
2025-01-14 00:13:22,858 - entropy         : 0
2025-01-14 00:13:22,866 - Dataset Creati
2025-01-14 00:13:22,866 - Training images: 5125
2025-01-14 00:13:22,866 - Validation images: 1031

2025-01-14 00:13:22,867 - Dataloader Creati
2025-01-14 00:13:22,867 - Training batches: 320
2025-01-14 00:13:22,867 - Validation batches: 128

2025-01-14 00:13:24,577 - Model: deeplabv3plus_mobilenet

2025-01-14 00:13:24,592 - Modello caricato correttamente su cuda:4

2025-01-14 00:13:24,594 - Inizio del training
2025-01-14 00:13:24,594 - optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 1e-05
    maximize: False
    weight_decay: 0.0001
)
2025-01-14 00:13:24,594 - loss:      CrossEntropyLoss()
2025-01-14 00:13:24,594 - epochs:    15
2025-01-14 00:13:24,594 - name:      weights_0

2025-01-14 00:16:34,423 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-14 00:16:34,424 - 0        1.269852   0.841728   0.227915   0.000000   0.799304   1.0e-04 , 1.0e-05 
2025-01-14 00:19:44,207 - 1        0.850832   0.774789   0.249682   0.000000   0.810120   1.0e-04 , 1.0e-05 
2025-01-14 00:19:44,208 - > saved mIoU
2025-01-14 00:22:46,391 - 2        0.776507   0.737703   0.263530   0.000000   0.812192   1.0e-04 , 1.0e-05 
2025-01-14 00:22:46,391 - > saved mIoU
2025-01-14 00:25:47,110 - 3        0.734416   0.740892   0.270577   0.000000   0.805725   1.0e-04 , 1.0e-05 
2025-01-14 00:25:47,110 - > saved mIoU
2025-01-14 00:28:51,658 - 4        0.711671   0.716371   0.279079   0.000000   0.817689   1.0e-04 , 1.0e-05 
2025-01-14 00:28:51,658 - > saved mIoU
2025-01-14 00:31:57,363 - 5        0.682726   0.698833   0.282499   0.000000   0.825807   1.0e-04 , 1.0e-05 
2025-01-14 00:31:57,363 - > saved mIoU
2025-01-14 00:35:04,617 - 6        0.664372   0.716946   0.287005   0.000000   0.824616   1.0e-04 , 1.0e-05 
2025-01-14 00:35:04,617 - > saved mIoU
2025-01-14 00:38:04,226 - 7        0.654517   0.686067   0.296052   0.000000   0.824239   1.0e-04 , 1.0e-05 
2025-01-14 00:38:04,226 - > saved mIoU
2025-01-14 00:41:11,494 - 8        0.643791   0.685704   0.298115   0.000000   0.828068   1.0e-04 , 1.0e-05 
2025-01-14 00:41:11,495 - > saved mIoU
2025-01-14 00:44:20,132 - 9        0.628514   0.667487   0.307196   0.000000   0.829803   1.0e-04 , 1.0e-05 
2025-01-14 00:44:20,132 - > saved mIoU
2025-01-14 00:47:31,347 - 10       0.622326   0.684070   0.301246   0.000000   0.816456   1.0e-04 , 1.0e-05 
2025-01-14 00:50:37,856 - 11       0.610885   0.693517   0.306734   0.000000   0.817352   1.0e-04 , 1.0e-05 
2025-01-14 00:53:45,963 - 12       0.609599   0.666948   0.314864   0.000345   0.827755   1.0e-04 , 1.0e-05 
2025-01-14 00:53:45,963 - > saved mIoU
2025-01-14 00:56:52,396 - 13       0.606040   0.673118   0.313926   0.001231   0.827349   1.0e-04 , 1.0e-05 
2025-01-14 00:59:59,669 - 14       0.593068   0.652357   0.320553   0.000443   0.823108   1.0e-04 , 1.0e-05 
2025-01-14 00:59:59,669 - > saved mIoU
2025-01-14 00:59:59,747 - Fine del training

2025-01-14 00:59:59,828 - 
Caricati i pesi in: /raid/homespace/piecestola/space/ML4CV/results/train_4/ckpts/weights_mIoU_0.pt

2025-01-14 00:59:59,829 - Inizio del training
2025-01-14 00:59:59,829 - optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 1e-05
    maximize: False
    weight_decay: 0.0001
)
2025-01-14 00:59:59,829 - loss:      CrossEntropyLoss()
2025-01-14 00:59:59,830 - epochs:    50
2025-01-14 00:59:59,830 - name:      weights_1

2025-01-14 01:05:28,757 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-14 01:05:28,758 - 0        0.483510   0.502838   0.376710   0.000049   0.867004   1.0e-04 , 1.0e-05 
2025-01-14 01:10:56,675 - 1        0.389051   0.465508   0.407655   0.010499   0.875888   1.0e-04 , 1.0e-05 
2025-01-14 01:10:56,675 - > saved mIoU
2025-01-14 01:16:26,237 - 2        0.334772   0.457849   0.427791   0.057873   0.879878   1.0e-04 , 1.0e-05 
2025-01-14 01:16:26,237 - > saved mIoU
2025-01-14 01:21:53,198 - 3        0.297053   0.425417   0.457601   0.059530   0.882084   1.0e-04 , 1.0e-05 
2025-01-14 01:21:53,199 - > saved mIoU
2025-01-14 01:27:19,233 - 4        0.268771   0.412224   0.483254   0.076062   0.887208   1.0e-04 , 1.0e-05 
2025-01-14 01:27:19,233 - > saved mIoU
2025-01-14 01:32:45,113 - 5        0.246395   0.427675   0.483516   0.083482   0.885073   1.0e-04 , 1.0e-05 
2025-01-14 01:32:45,113 - > saved mIoU
2025-01-14 01:38:11,134 - 6        0.228408   0.426917   0.494073   0.105354   0.880169   1.0e-04 , 1.0e-05 
2025-01-14 01:38:11,134 - > saved mIoU
2025-01-14 01:43:32,670 - 7        0.214880   0.422778   0.497242   0.093028   0.888892   1.0e-04 , 1.0e-05 
2025-01-14 01:43:32,670 - > saved mIoU
2025-01-14 01:48:53,918 - 8        0.200855   0.402693   0.512730   0.120345   0.887952   1.0e-04 , 1.0e-05 
2025-01-14 01:48:53,918 - > saved mIoU
2025-01-14 01:54:13,912 - 9        0.191787   0.422576   0.508354   0.131339   0.892146   1.0e-04 , 1.0e-05 
2025-01-14 01:59:36,715 - 10       0.182480   0.428813   0.511282   0.129287   0.892198   1.0e-04 , 1.0e-05 
2025-01-14 02:04:59,834 - 11       0.174912   0.419964   0.514958   0.127916   0.897001   1.0e-04 , 1.0e-05 
2025-01-14 02:04:59,834 - > saved mIoU
2025-01-14 02:10:22,491 - 12       0.166734   0.437933   0.513330   0.122666   0.893826   1.0e-04 , 1.0e-05 
2025-01-14 02:15:43,498 - 13       0.161840   0.424103   0.518671   0.142610   0.894948   1.0e-04 , 1.0e-05 
2025-01-14 02:15:43,499 - > saved mIoU
2025-01-14 02:21:04,729 - 14       0.154870   0.428049   0.515942   0.141500   0.898407   1.0e-04 , 1.0e-05 
2025-01-14 02:26:25,165 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-14 02:26:25,166 - 15       0.149298   0.414511   0.527757   0.147377   0.896860   1.0e-04 , 1.0e-05 
2025-01-14 02:26:25,166 - > saved mIoU
2025-01-14 02:31:45,640 - 16       0.143100   0.431739   0.523665   0.163874   0.895310   1.0e-04 , 1.0e-05 
2025-01-14 02:37:06,466 - 17       0.138303   0.438227   0.521535   0.143523   0.897777   1.0e-04 , 1.0e-05 
2025-01-14 02:42:27,932 - 18       0.135405   0.410999   0.523212   0.179046   0.899138   1.0e-04 , 1.0e-05 
2025-01-14 02:47:48,492 - 19       0.130879   0.426574   0.524428   0.159508   0.901191   1.0e-04 , 1.0e-05 
2025-01-14 02:53:11,998 - 20       0.126236   0.412763   0.537698   0.172559   0.902064   1.0e-04 , 1.0e-05 
2025-01-14 02:53:11,998 - > saved mIoU
2025-01-14 02:58:36,281 - 21       0.123610   0.419295   0.537819   0.161779   0.897138   1.0e-04 , 1.0e-05 
2025-01-14 02:58:36,281 - > saved mIoU
2025-01-14 03:03:57,715 - 22       0.119869   0.422312   0.540864   0.166345   0.894903   5.0e-05 , 5.0e-06 
2025-01-14 03:03:57,716 - > saved mIoU
2025-01-14 03:09:18,474 - 23       0.115726   0.417937   0.545374   0.176440   0.901356   5.0e-05 , 5.0e-06 
2025-01-14 03:09:18,474 - > saved mIoU
2025-01-14 03:14:39,042 - 24       0.115469   0.422894   0.546909   0.173194   0.902235   5.0e-05 , 5.0e-06 
2025-01-14 03:14:39,043 - > saved mIoU
2025-01-14 03:20:01,491 - 25       0.111769   0.422322   0.541252   0.149886   0.898511   5.0e-05 , 5.0e-06 
2025-01-14 03:25:22,494 - 26       0.110813   0.416093   0.545173   0.145582   0.896851   5.0e-05 , 5.0e-06 
2025-01-14 03:30:44,389 - 27       0.108807   0.410303   0.549909   0.166076   0.902517   5.0e-05 , 5.0e-06 
2025-01-14 03:30:44,389 - > saved mIoU
2025-01-14 03:36:06,850 - 28       0.107408   0.407065   0.549453   0.151080   0.903379   5.0e-05 , 5.0e-06 
2025-01-14 03:41:30,197 - 29       0.105908   0.413875   0.546271   0.143396   0.907489   5.0e-05 , 5.0e-06 
2025-01-14 03:46:50,513 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-14 03:46:50,514 - 30       0.104160   0.421084   0.546835   0.147896   0.909210   5.0e-05 , 5.0e-06 
2025-01-14 03:52:10,798 - 31       0.102714   0.408361   0.547296   0.158842   0.908674   5.0e-05 , 5.0e-06 
2025-01-14 03:57:32,009 - 32       0.100992   0.398467   0.553604   0.154341   0.909532   5.0e-05 , 5.0e-06 
2025-01-14 03:57:32,009 - > saved mIoU
2025-01-14 04:02:52,761 - 33       0.099908   0.403100   0.553941   0.200848   0.907077   5.0e-05 , 5.0e-06 
2025-01-14 04:02:52,762 - > saved mIoU
2025-01-14 04:08:14,685 - 34       0.099178   0.403337   0.555773   0.193848   0.905358   5.0e-05 , 5.0e-06 
2025-01-14 04:08:14,686 - > saved mIoU
2025-01-14 04:13:35,717 - 35       0.097144   0.418726   0.553606   0.194117   0.906088   5.0e-05 , 5.0e-06 
2025-01-14 04:18:56,284 - 36       0.097552   0.410514   0.560509   0.237515   0.908357   5.0e-05 , 5.0e-06 
2025-01-14 04:18:56,285 - > saved mIoU
2025-01-14 04:24:17,332 - 37       0.096148   0.419765   0.551973   0.181429   0.906432   5.0e-05 , 5.0e-06 
2025-01-14 04:29:37,902 - 38       0.094236   0.407321   0.553024   0.172742   0.907977   5.0e-05 , 5.0e-06 
2025-01-14 04:34:59,774 - 39       0.093848   0.413169   0.558354   0.204263   0.910763   5.0e-05 , 5.0e-06 
2025-01-14 04:40:20,520 - 40       0.092582   0.413079   0.555912   0.195220   0.907136   5.0e-05 , 5.0e-06 
2025-01-14 04:45:40,117 - 41       0.092258   0.411289   0.552443   0.176799   0.906566   5.0e-05 , 5.0e-06 
2025-01-14 04:51:00,318 - 42       0.091601   0.395557   0.562477   0.184138   0.911977   5.0e-05 , 5.0e-06 
2025-01-14 04:51:00,319 - > saved mIoU
2025-01-14 04:56:20,514 - 43       0.090399   0.409081   0.551834   0.174819   0.913808   5.0e-05 , 5.0e-06 
2025-01-14 05:01:40,948 - 44       0.090069   0.403634   0.557552   0.171455   0.912628   5.0e-05 , 5.0e-06 
2025-01-14 05:07:02,266 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-14 05:07:02,267 - 45       0.089033   0.429242   0.555230   0.174418   0.912153   5.0e-05 , 5.0e-06 
2025-01-14 05:12:22,285 - 46       0.087728   0.423337   0.557504   0.162931   0.912363   5.0e-05 , 5.0e-06 
2025-01-14 05:17:42,049 - 47       0.087733   0.425897   0.537751   0.146185   0.915004   5.0e-05 , 5.0e-06 
2025-01-14 05:23:02,753 - 48       0.086530   0.434080   0.543974   0.157255   0.913661   5.0e-05 , 5.0e-06 
2025-01-14 05:28:24,047 - 49       0.087671   0.424168   0.553213   0.167406   0.913024   5.0e-05 , 5.0e-06 
2025-01-14 05:28:24,047 - Fine del training

