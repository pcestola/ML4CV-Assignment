2025-01-31 12:18:13,127 - device          : cuda:1
2025-01-31 12:18:13,127 - model           : resnet101
2025-01-31 12:18:13,127 - mlp             : 0
2025-01-31 12:18:13,127 - vae             : False
2025-01-31 12:18:13,128 - epochs          : 50
2025-01-31 12:18:13,128 - batch           : 16
2025-01-31 12:18:13,128 - lr              : 0.0001
2025-01-31 12:18:13,128 - crop            : 512
2025-01-31 12:18:13,128 - optimizer       : adam
2025-01-31 12:18:13,128 - biases          : False
2025-01-31 12:18:13,128 - focal_loss      : 0
2025-01-31 12:18:13,128 - activation      : softmax
2025-01-31 12:18:13,128 - class_weights   : False
2025-01-31 12:18:13,128 - norm_weights    : False
2025-01-31 12:18:13,128 - p               : 0.3
2025-01-31 12:18:13,128 - entropy         : 0.1
2025-01-31 12:18:13,136 - Dataset Creati
2025-01-31 12:18:13,136 - Training images: 5125
2025-01-31 12:18:13,136 - Validation images: 1031

2025-01-31 12:18:13,136 - Dataloader Creati
2025-01-31 12:18:13,136 - Training batches: 320
2025-01-31 12:18:13,136 - Validation batches: 128

2025-01-31 12:18:16,648 - Model: deeplabv3plus_resnet101

2025-01-31 12:18:16,712 - Modello caricato correttamente su cuda:1

2025-01-31 12:18:16,714 - Inizio del training
2025-01-31 12:18:16,714 - optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 1e-05
    maximize: False
    weight_decay: 0.0001
)
2025-01-31 12:18:16,715 - loss:      CE_EntropyMinimization(
  (ce_loss): CrossEntropyLoss()
)
2025-01-31 12:18:16,715 - epochs:    15
2025-01-31 12:18:16,715 - name:      weights_0

2025-01-31 12:24:33,297 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-31 12:24:33,298 - 0        1.246823   0.896982   0.257599   0.000000   0.777264   1.0e-04 , 1.0e-05 
2025-01-31 12:30:49,282 - 1        0.873259   0.801492   0.288305   0.000000   0.803065   1.0e-04 , 1.0e-05 
2025-01-31 12:30:49,282 - > saved mIoU
2025-01-31 12:37:05,570 - 2        0.791460   0.748760   0.303875   0.000000   0.812313   1.0e-04 , 1.0e-05 
2025-01-31 12:37:05,570 - > saved mIoU
2025-01-31 12:43:22,195 - 3        0.740034   0.738310   0.308457   0.000000   0.815635   1.0e-04 , 1.0e-05 
2025-01-31 12:43:22,196 - > saved mIoU
2025-01-31 12:49:38,264 - 4        0.720323   0.744923   0.318121   0.000000   0.814534   1.0e-04 , 1.0e-05 
2025-01-31 12:49:38,264 - > saved mIoU
2025-01-31 12:55:54,433 - 5        0.698016   0.765313   0.318910   0.000000   0.802607   1.0e-04 , 1.0e-05 
2025-01-31 12:55:54,433 - > saved mIoU
2025-01-31 13:02:10,828 - 6        0.675797   0.732509   0.328211   0.000000   0.817566   1.0e-04 , 1.0e-05 
2025-01-31 13:02:10,829 - > saved mIoU
2025-01-31 13:08:27,183 - 7        0.657759   0.728630   0.329869   0.000000   0.822676   1.0e-04 , 1.0e-05 
2025-01-31 13:08:27,183 - > saved mIoU
2025-01-31 13:14:43,546 - 8        0.645393   0.717907   0.338428   0.000000   0.823855   1.0e-04 , 1.0e-05 
2025-01-31 13:14:43,546 - > saved mIoU
2025-01-31 13:20:59,843 - 9        0.631323   0.731315   0.337175   0.000000   0.824917   1.0e-04 , 1.0e-05 
2025-01-31 13:27:15,598 - 10       0.622983   0.741300   0.344528   0.000000   0.818439   1.0e-04 , 1.0e-05 
2025-01-31 13:27:15,598 - > saved mIoU
2025-01-31 13:33:31,691 - 11       0.614135   0.751013   0.345803   0.000000   0.816220   1.0e-04 , 1.0e-05 
2025-01-31 13:33:31,692 - > saved mIoU
2025-01-31 13:39:47,926 - 12       0.610059   0.735371   0.350209   0.000000   0.817129   1.0e-04 , 1.0e-05 
2025-01-31 13:39:47,927 - > saved mIoU
2025-01-31 13:46:04,194 - 13       0.593262   0.740674   0.349253   0.000000   0.823713   1.0e-04 , 1.0e-05 
2025-01-31 13:52:19,982 - 14       0.597919   0.756557   0.350165   0.001033   0.815787   1.0e-04 , 1.0e-05 
2025-01-31 13:52:19,982 - Fine del training

2025-01-31 13:52:20,271 - 
Caricati i pesi in: /raid/homespace/piecestola/space/ML4CV/results/train_1/ckpts/weights_mIoU_0.pt

2025-01-31 13:52:20,272 - Inizio del training
2025-01-31 13:52:20,272 - optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 5e-05
    maximize: False
    weight_decay: 0.0001

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 5e-06
    maximize: False
    weight_decay: 0.0001
)
2025-01-31 13:52:20,272 - loss:      CE_EntropyMinimization(
  (ce_loss): CrossEntropyLoss()
)
2025-01-31 13:52:20,273 - epochs:    50
2025-01-31 13:52:20,273 - name:      weights_1

2025-01-31 14:08:06,133 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-31 14:08:06,134 - 0        0.494208   0.535491   0.412150   0.000000   0.877562   5.0e-05 , 5.0e-06 
2025-01-31 14:23:54,066 - 1        0.368909   0.491772   0.443046   0.000000   0.902077   5.0e-05 , 5.0e-06 
2025-01-31 14:23:54,066 - > saved mIoU
2025-01-31 14:39:42,144 - 2        0.308429   0.483458   0.455437   0.000000   0.898843   5.0e-05 , 5.0e-06 
2025-01-31 14:39:42,144 - > saved mIoU
2025-01-31 14:55:30,797 - 3        0.266359   0.466909   0.470064   0.038816   0.907485   5.0e-05 , 5.0e-06 
2025-01-31 14:55:30,798 - > saved mIoU
2025-01-31 15:11:19,327 - 4        0.235905   0.448900   0.480042   0.083350   0.912780   5.0e-05 , 5.0e-06 
2025-01-31 15:11:19,327 - > saved mIoU
2025-01-31 15:27:12,085 - 5        0.216991   0.466393   0.503571   0.190698   0.914644   5.0e-05 , 5.0e-06 
2025-01-31 15:27:12,086 - > saved mIoU
2025-01-31 15:43:08,420 - 6        0.199339   0.453183   0.522045   0.194085   0.914545   5.0e-05 , 5.0e-06 
2025-01-31 15:43:08,421 - > saved mIoU
2025-01-31 15:59:04,256 - 7        0.187582   0.459623   0.522986   0.210855   0.917522   5.0e-05 , 5.0e-06 
2025-01-31 15:59:04,257 - > saved mIoU
2025-01-31 16:15:00,285 - 8        0.178380   0.453487   0.526431   0.200181   0.917108   5.0e-05 , 5.0e-06 
2025-01-31 16:15:00,285 - > saved mIoU
2025-01-31 16:30:57,677 - 9        0.164529   0.442934   0.540729   0.222677   0.920839   5.0e-05 , 5.0e-06 
2025-01-31 16:30:57,678 - > saved mIoU
2025-01-31 16:47:00,608 - 10       0.156010   0.432777   0.550881   0.228134   0.925520   5.0e-05 , 5.0e-06 
2025-01-31 16:47:00,609 - > saved mIoU
2025-01-31 17:03:02,860 - 11       0.149213   0.420152   0.561158   0.242947   0.926589   5.0e-05 , 5.0e-06 
2025-01-31 17:03:02,860 - > saved mIoU
2025-01-31 17:19:02,632 - 12       0.142687   0.445185   0.552869   0.246678   0.923920   5.0e-05 , 5.0e-06 
2025-01-31 17:35:00,587 - 13       0.137349   0.431549   0.567779   0.246402   0.928208   5.0e-05 , 5.0e-06 
2025-01-31 17:35:00,587 - > saved mIoU
2025-01-31 17:51:01,328 - 14       0.133438   0.418238   0.572539   0.254598   0.927027   5.0e-05 , 5.0e-06 
2025-01-31 17:51:01,329 - > saved mIoU
2025-01-31 18:07:02,118 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-31 18:07:02,119 - 15       0.132577   0.394584   0.570408   0.258253   0.925855   5.0e-05 , 5.0e-06 
2025-01-31 18:22:54,219 - 16       0.129920   0.412946   0.581400   0.264788   0.927030   5.0e-05 , 5.0e-06 
2025-01-31 18:22:54,219 - > saved mIoU
2025-01-31 18:38:48,762 - 17       0.123606   0.390749   0.587092   0.258482   0.927805   5.0e-05 , 5.0e-06 
2025-01-31 18:38:48,763 - > saved mIoU
2025-01-31 18:54:48,516 - 18       0.118733   0.421331   0.584698   0.276526   0.924022   5.0e-05 , 5.0e-06 
2025-01-31 19:10:46,978 - 19       0.115540   0.406934   0.590584   0.260850   0.923781   5.0e-05 , 5.0e-06 
2025-01-31 19:10:46,979 - > saved mIoU
2025-01-31 19:26:48,149 - 20       0.112302   0.425272   0.583479   0.280164   0.921438   5.0e-05 , 5.0e-06 
2025-01-31 19:42:49,242 - 21       0.108548   0.399568   0.599757   0.288478   0.930885   5.0e-05 , 5.0e-06 
2025-01-31 19:42:49,242 - > saved mIoU
2025-01-31 19:58:50,917 - 22       0.107884   0.429254   0.581905   0.276149   0.924886   5.0e-05 , 5.0e-06 
2025-01-31 20:14:49,645 - 23       0.108233   0.381722   0.602318   0.302876   0.930416   5.0e-05 , 5.0e-06 
2025-01-31 20:14:49,646 - > saved mIoU
2025-01-31 20:30:48,349 - 24       0.104425   0.421221   0.587370   0.272388   0.929094   5.0e-05 , 5.0e-06 
2025-01-31 20:46:44,094 - 25       0.104543   0.399162   0.604859   0.294329   0.932716   5.0e-05 , 5.0e-06 
2025-01-31 20:46:44,094 - > saved mIoU
2025-01-31 21:02:40,274 - 26       0.100292   0.417870   0.595755   0.314138   0.928994   5.0e-05 , 5.0e-06 
2025-01-31 21:18:35,465 - 27       0.098968   0.407420   0.587802   0.285845   0.933199   5.0e-05 , 5.0e-06 
2025-01-31 21:34:30,711 - 28       0.099474   0.369004   0.596445   0.308449   0.930590   5.0e-05 , 5.0e-06 
2025-01-31 21:50:26,440 - 29       0.100541   0.409798   0.591898   0.300381   0.935330   5.0e-05 , 5.0e-06 
2025-01-31 22:06:20,275 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-31 22:06:20,275 - 30       0.094799   0.393914   0.610352   0.319579   0.933204   5.0e-05 , 5.0e-06 
2025-01-31 22:06:20,276 - > saved mIoU
2025-01-31 22:22:16,810 - 31       0.092478   0.412517   0.599687   0.313469   0.931128   5.0e-05 , 5.0e-06 
2025-01-31 22:38:11,860 - 32       0.092315   0.390005   0.605909   0.321810   0.931229   5.0e-05 , 5.0e-06 
2025-01-31 22:54:07,231 - 33       0.090419   0.379725   0.608608   0.316496   0.931196   5.0e-05 , 5.0e-06 
2025-01-31 23:10:03,197 - 34       0.097581   0.533277   0.520170   0.153119   0.901124   5.0e-05 , 5.0e-06 
2025-01-31 23:25:58,890 - 35       0.098029   0.427894   0.601008   0.328124   0.928604   2.5e-05 , 2.5e-06 
2025-01-31 23:41:54,685 - 36       0.091298   0.440273   0.591111   0.319499   0.922225   2.5e-05 , 2.5e-06 
2025-01-31 23:57:50,306 - 37       0.086897   0.433900   0.600037   0.321785   0.925771   2.5e-05 , 2.5e-06 
2025-02-01 00:13:46,705 - 38       0.085574   0.431284   0.598865   0.331421   0.929995   2.5e-05 , 2.5e-06 
2025-02-01 00:29:43,340 - 39       0.085160   0.413463   0.606783   0.308252   0.929676   2.5e-05 , 2.5e-06 
2025-02-01 00:45:38,762 - 40       0.082577   0.425200   0.604461   0.334273   0.929292   2.5e-05 , 2.5e-06 
2025-02-01 01:01:34,062 - 41       0.082194   0.419570   0.602383   0.299367   0.930121   1.3e-05 , 1.3e-06 
2025-02-01 01:17:29,841 - 42       0.081197   0.432326   0.603494   0.326846   0.929093   1.3e-05 , 1.3e-06 
2025-02-01 01:33:25,174 - 43       0.080581   0.426891   0.603549   0.330676   0.929611   1.3e-05 , 1.3e-06 
2025-02-01 01:49:22,323 - 44       0.080546   0.433942   0.605015   0.320435   0.929419   1.3e-05 , 1.3e-06 
2025-02-01 02:05:16,594 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-02-01 02:05:16,595 - 45       0.079866   0.444150   0.604028   0.324033   0.929474   1.3e-05 , 1.3e-06 
2025-02-01 02:21:14,151 - 46       0.079245   0.433749   0.602489   0.317489   0.929341   1.3e-05 , 1.3e-06 
2025-02-01 02:37:10,665 - 47       0.078899   0.429199   0.606888   0.336261   0.928332   6.3e-06 , 6.3e-07 
2025-02-01 02:53:05,766 - 48       0.078334   0.434777   0.605265   0.338434   0.929004   6.3e-06 , 6.3e-07 
2025-02-01 03:09:00,559 - 49       0.077860   0.435811   0.603437   0.333440   0.929839   6.3e-06 , 6.3e-07 
2025-02-01 03:09:00,560 - Fine del training

