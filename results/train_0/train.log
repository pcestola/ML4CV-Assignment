2025-01-31 12:17:55,628 - device          : cuda:0
2025-01-31 12:17:55,628 - model           : resnet101
2025-01-31 12:17:55,628 - mlp             : 0
2025-01-31 12:17:55,628 - vae             : False
2025-01-31 12:17:55,628 - epochs          : 50
2025-01-31 12:17:55,628 - batch           : 16
2025-01-31 12:17:55,628 - lr              : 0.0001
2025-01-31 12:17:55,628 - crop            : 512
2025-01-31 12:17:55,628 - optimizer       : adam
2025-01-31 12:17:55,628 - biases          : False
2025-01-31 12:17:55,628 - focal_loss      : 0
2025-01-31 12:17:55,628 - activation      : softmax
2025-01-31 12:17:55,628 - class_weights   : False
2025-01-31 12:17:55,628 - norm_weights    : False
2025-01-31 12:17:55,628 - p               : 0.3
2025-01-31 12:17:55,629 - entropy         : 0.1
2025-01-31 12:17:55,637 - Dataset Creati
2025-01-31 12:17:55,637 - Training images: 5125
2025-01-31 12:17:55,637 - Validation images: 1031

2025-01-31 12:17:55,637 - Dataloader Creati
2025-01-31 12:17:55,637 - Training batches: 320
2025-01-31 12:17:55,637 - Validation batches: 128

2025-01-31 12:17:59,226 - Model: deeplabv3plus_resnet101

2025-01-31 12:17:59,289 - Modello caricato correttamente su cuda:0

2025-01-31 12:17:59,292 - Inizio del training
2025-01-31 12:17:59,292 - optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 1e-05
    maximize: False
    weight_decay: 0.0001
)
2025-01-31 12:17:59,292 - loss:      CE_EntropyMinimization(
  (ce_loss): CrossEntropyLoss()
)
2025-01-31 12:17:59,292 - epochs:    15
2025-01-31 12:17:59,292 - name:      weights_0

2025-01-31 12:24:15,634 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-31 12:24:15,635 - 0        1.048510   0.719918   0.286578   0.000000   0.819258   1.0e-04 , 1.0e-05 
2025-01-31 12:30:32,597 - 1        0.747994   0.682045   0.308584   0.000000   0.829985   1.0e-04 , 1.0e-05 
2025-01-31 12:30:32,597 - > saved mIoU
2025-01-31 12:36:50,153 - 2        0.679934   0.666481   0.324323   0.000000   0.832119   1.0e-04 , 1.0e-05 
2025-01-31 12:36:50,153 - > saved mIoU
2025-01-31 12:43:07,524 - 3        0.630566   0.657937   0.333440   0.000000   0.836453   1.0e-04 , 1.0e-05 
2025-01-31 12:43:07,525 - > saved mIoU
2025-01-31 12:49:24,641 - 4        0.612389   0.644203   0.340629   0.000000   0.842122   1.0e-04 , 1.0e-05 
2025-01-31 12:49:24,642 - > saved mIoU
2025-01-31 12:55:41,865 - 5        0.594454   0.655470   0.344129   0.005015   0.837594   1.0e-04 , 1.0e-05 
2025-01-31 12:55:41,865 - > saved mIoU
2025-01-31 13:01:58,867 - 6        0.571620   0.650789   0.353125   0.010932   0.841529   1.0e-04 , 1.0e-05 
2025-01-31 13:01:58,867 - > saved mIoU
2025-01-31 13:08:16,292 - 7        0.557005   0.636666   0.360753   0.014792   0.844805   1.0e-04 , 1.0e-05 
2025-01-31 13:08:16,292 - > saved mIoU
2025-01-31 13:14:33,680 - 8        0.544943   0.642598   0.370366   0.017321   0.845265   1.0e-04 , 1.0e-05 
2025-01-31 13:14:33,681 - > saved mIoU
2025-01-31 13:20:51,341 - 9        0.530881   0.643763   0.376996   0.018995   0.849519   1.0e-04 , 1.0e-05 
2025-01-31 13:20:51,341 - > saved mIoU
2025-01-31 13:27:08,612 - 10       0.523128   0.644092   0.388755   0.023810   0.851898   1.0e-04 , 1.0e-05 
2025-01-31 13:27:08,612 - > saved mIoU
2025-01-31 13:33:25,406 - 11       0.515406   0.650155   0.386725   0.024722   0.846004   1.0e-04 , 1.0e-05 
2025-01-31 13:39:42,111 - 12       0.509891   0.653589   0.397329   0.025476   0.847998   1.0e-04 , 1.0e-05 
2025-01-31 13:39:42,112 - > saved mIoU
2025-01-31 13:45:59,584 - 13       0.497340   0.647937   0.403567   0.029380   0.849697   1.0e-04 , 1.0e-05 
2025-01-31 13:45:59,584 - > saved mIoU
2025-01-31 13:52:16,797 - 14       0.497651   0.654233   0.404187   0.034009   0.850179   5.0e-05 , 5.0e-06 
2025-01-31 13:52:16,798 - > saved mIoU
2025-01-31 13:52:17,282 - Fine del training

2025-01-31 13:52:17,522 - 
Caricati i pesi in: /raid/homespace/piecestola/space/ML4CV/results/train_0/ckpts/weights_mIoU_0.pt

2025-01-31 13:52:17,527 - Inizio del training
2025-01-31 13:52:17,527 - optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 5e-05
    maximize: False
    weight_decay: 0.0001

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 5e-06
    maximize: False
    weight_decay: 0.0001
)
2025-01-31 13:52:17,527 - loss:      CE_EntropyMinimization(
  (ce_loss): CrossEntropyLoss()
)
2025-01-31 13:52:17,527 - epochs:    50
2025-01-31 13:52:17,527 - name:      weights_1

2025-01-31 14:08:03,425 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-31 14:08:03,425 - 0        0.422274   0.520969   0.460536   0.051701   0.901741   5.0e-05 , 5.0e-06 
2025-01-31 14:23:50,547 - 1        0.317243   0.486763   0.488925   0.104699   0.913869   5.0e-05 , 5.0e-06 
2025-01-31 14:23:50,548 - > saved mIoU
2025-01-31 14:39:38,669 - 2        0.260844   0.464811   0.509114   0.126643   0.911583   5.0e-05 , 5.0e-06 
2025-01-31 14:39:38,670 - > saved mIoU
2025-01-31 14:55:27,148 - 3        0.224245   0.452146   0.515307   0.143912   0.916472   5.0e-05 , 5.0e-06 
2025-01-31 14:55:27,148 - > saved mIoU
2025-01-31 15:11:15,890 - 4        0.197329   0.439028   0.531128   0.161735   0.924699   5.0e-05 , 5.0e-06 
2025-01-31 15:11:15,891 - > saved mIoU
2025-01-31 15:27:08,255 - 5        0.179844   0.437506   0.543206   0.209693   0.920398   5.0e-05 , 5.0e-06 
2025-01-31 15:27:08,256 - > saved mIoU
2025-01-31 15:43:05,119 - 6        0.165764   0.438027   0.549260   0.214228   0.924621   5.0e-05 , 5.0e-06 
2025-01-31 15:43:05,120 - > saved mIoU
2025-01-31 15:59:00,777 - 7        0.156448   0.439124   0.548697   0.205705   0.920216   5.0e-05 , 5.0e-06 
2025-01-31 16:14:56,707 - 8        0.148508   0.428866   0.557393   0.189628   0.920522   5.0e-05 , 5.0e-06 
2025-01-31 16:14:56,707 - > saved mIoU
2025-01-31 16:30:55,568 - 9        0.138187   0.435971   0.565037   0.216007   0.927337   5.0e-05 , 5.0e-06 
2025-01-31 16:30:55,568 - > saved mIoU
2025-01-31 16:47:00,657 - 10       0.131724   0.426244   0.578015   0.261143   0.927162   5.0e-05 , 5.0e-06 
2025-01-31 16:47:00,658 - > saved mIoU
2025-01-31 17:03:04,764 - 11       0.126404   0.413831   0.575590   0.227624   0.921333   5.0e-05 , 5.0e-06 
2025-01-31 17:19:04,769 - 12       0.121346   0.427228   0.576103   0.216807   0.927834   5.0e-05 , 5.0e-06 
2025-01-31 17:35:05,231 - 13       0.117480   0.431293   0.579334   0.210597   0.928625   5.0e-05 , 5.0e-06 
2025-01-31 17:35:05,231 - > saved mIoU
2025-01-31 17:51:06,072 - 14       0.114493   0.422749   0.590939   0.251533   0.928708   5.0e-05 , 5.0e-06 
2025-01-31 17:51:06,073 - > saved mIoU
2025-01-31 18:07:09,127 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-31 18:07:09,128 - 15       0.112887   0.418422   0.574934   0.179271   0.915117   5.0e-05 , 5.0e-06 
2025-01-31 18:23:02,408 - 16       0.109023   0.395163   0.601480   0.274515   0.930541   5.0e-05 , 5.0e-06 
2025-01-31 18:23:02,408 - > saved mIoU
2025-01-31 18:38:56,962 - 17       0.109648   0.391793   0.578380   0.266161   0.920420   5.0e-05 , 5.0e-06 
2025-01-31 18:54:57,733 - 18       0.114551   0.400797   0.604938   0.277575   0.928144   5.0e-05 , 5.0e-06 
2025-01-31 18:54:57,734 - > saved mIoU
2025-01-31 19:10:58,835 - 19       0.109910   0.416256   0.602768   0.279161   0.933871   5.0e-05 , 5.0e-06 
2025-01-31 19:26:59,887 - 20       0.103302   0.422373   0.603484   0.280166   0.933138   5.0e-05 , 5.0e-06 
2025-01-31 19:43:01,257 - 21       0.097449   0.421455   0.601022   0.232348   0.934331   5.0e-05 , 5.0e-06 
2025-01-31 19:59:03,349 - 22       0.095147   0.439773   0.595125   0.229909   0.931205   5.0e-05 , 5.0e-06 
2025-01-31 20:15:03,913 - 23       0.095009   0.411328   0.612019   0.243578   0.934872   5.0e-05 , 5.0e-06 
2025-01-31 20:15:03,913 - > saved mIoU
2025-01-31 20:31:05,179 - 24       0.093044   0.439818   0.607502   0.311646   0.931094   2.5e-05 , 2.5e-06 
2025-01-31 20:47:02,796 - 25       0.090943   0.422524   0.607414   0.287550   0.932170   2.5e-05 , 2.5e-06 
2025-01-31 21:02:58,996 - 26       0.088424   0.415141   0.614060   0.282192   0.930746   2.5e-05 , 2.5e-06 
2025-01-31 21:02:58,996 - > saved mIoU
2025-01-31 21:18:57,569 - 27       0.086220   0.418843   0.616986   0.322104   0.934143   2.5e-05 , 2.5e-06 
2025-01-31 21:18:57,569 - > saved mIoU
2025-01-31 21:34:56,636 - 28       0.085332   0.414125   0.615513   0.282028   0.933683   2.5e-05 , 2.5e-06 
2025-01-31 21:50:53,691 - 29       0.085036   0.417986   0.603192   0.290455   0.934083   2.5e-05 , 2.5e-06 
2025-01-31 22:06:48,863 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-31 22:06:48,863 - 30       0.083753   0.417624   0.617813   0.323473   0.931301   1.3e-05 , 1.3e-06 
2025-01-31 22:06:48,863 - > saved mIoU
2025-01-31 22:22:47,011 - 31       0.082098   0.413177   0.618732   0.322355   0.933045   1.3e-05 , 1.3e-06 
2025-01-31 22:22:47,011 - > saved mIoU
2025-01-31 22:38:45,006 - 32       0.082247   0.412535   0.621247   0.327310   0.935660   1.3e-05 , 1.3e-06 
2025-01-31 22:38:45,006 - > saved mIoU
2025-01-31 22:54:42,507 - 33       0.080095   0.420226   0.615145   0.304525   0.935283   1.3e-05 , 1.3e-06 
2025-01-31 23:10:38,795 - 34       0.080179   0.419400   0.616520   0.299266   0.935216   1.3e-05 , 1.3e-06 
2025-01-31 23:26:33,725 - 35       0.079110   0.412146   0.618602   0.303296   0.934636   1.3e-05 , 1.3e-06 
2025-01-31 23:42:29,193 - 36       0.078962   0.415673   0.623620   0.311123   0.937322   6.3e-06 , 6.3e-07 
2025-01-31 23:42:29,193 - > saved mIoU
2025-01-31 23:58:27,623 - 37       0.077944   0.418819   0.622998   0.316191   0.935941   6.3e-06 , 6.3e-07 
2025-02-01 00:14:23,927 - 38       0.077920   0.416679   0.624011   0.338785   0.936366   6.3e-06 , 6.3e-07 
2025-02-01 00:14:23,927 - > saved mIoU
2025-02-01 00:30:23,021 - 39       0.078541   0.408927   0.624235   0.337604   0.936536   6.3e-06 , 6.3e-07 
2025-02-01 00:30:23,022 - > saved mIoU
2025-02-01 00:46:20,581 - 40       0.076918   0.415569   0.624426   0.338534   0.934154   6.3e-06 , 6.3e-07 
2025-02-01 00:46:20,581 - > saved mIoU
2025-02-01 01:02:18,698 - 41       0.076425   0.411151   0.621085   0.314459   0.935944   6.3e-06 , 6.3e-07 
2025-02-01 01:18:15,489 - 42       0.076230   0.406595   0.628831   0.338730   0.935002   3.1e-06 , 3.1e-07 
2025-02-01 01:18:15,489 - > saved mIoU
2025-02-01 01:34:12,964 - 43       0.076219   0.404759   0.626309   0.333303   0.935909   3.1e-06 , 3.1e-07 
2025-02-01 01:50:10,811 - 44       0.076542   0.407244   0.625796   0.337948   0.935470   3.1e-06 , 3.1e-07 
2025-02-01 02:06:06,434 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-02-01 02:06:06,434 - 45       0.076011   0.409363   0.626256   0.334012   0.935785   3.1e-06 , 3.1e-07 
2025-02-01 02:22:03,746 - 46       0.075770   0.407005   0.627157   0.336954   0.935653   3.1e-06 , 3.1e-07 
2025-02-01 02:38:00,224 - 47       0.075454   0.405757   0.624611   0.328887   0.935555   3.1e-06 , 3.1e-07 
2025-02-01 02:53:58,434 - 48       0.075390   0.401164   0.627061   0.321348   0.936809   1.6e-06 , 1.6e-07 
2025-02-01 03:09:54,230 - 49       0.075164   0.404110   0.624270   0.309816   0.936234   1.6e-06 , 1.6e-07 
2025-02-01 03:09:54,230 - Fine del training

