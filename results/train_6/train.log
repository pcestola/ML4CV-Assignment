2025-01-31 18:37:48,535 - device          : cuda:7
2025-01-31 18:37:48,535 - model           : resnet101
2025-01-31 18:37:48,535 - mlp             : 0
2025-01-31 18:37:48,535 - p               : 0
2025-01-31 18:37:48,536 - epochs          : 50
2025-01-31 18:37:48,536 - batch           : 10
2025-01-31 18:37:48,536 - lr              : 0.0001
2025-01-31 18:37:48,536 - crop            : 512
2025-01-31 18:37:48,536 - optimizer       : adam
2025-01-31 18:37:48,536 - focal_loss      : 0
2025-01-31 18:37:48,536 - activation      : softmax
2025-01-31 18:37:48,536 - class_weights   : False
2025-01-31 18:37:48,536 - arc_face        : True
2025-01-31 18:37:48,536 - entropy         : 0
2025-01-31 18:37:48,546 - Dataset Creati
2025-01-31 18:37:48,546 - Training images: 5125
2025-01-31 18:37:48,546 - Validation images: 1031

2025-01-31 18:37:48,547 - Dataloader Creati
2025-01-31 18:37:48,547 - Training batches: 512
2025-01-31 18:37:48,548 - Validation batches: 128

2025-01-31 18:37:52,563 - Model: deeplabv3plus_resnet101

2025-01-31 18:37:52,638 - Modello caricato correttamente su cuda:7

2025-01-31 18:37:52,642 - Inizio del training
2025-01-31 18:37:52,642 - optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 1e-05
    maximize: False
    weight_decay: 0.0001
)
2025-01-31 18:37:52,642 - loss:      ArcFaceLoss(
  (loss): CrossEntropyLoss()
)
2025-01-31 18:37:52,642 - epochs:    15
2025-01-31 18:37:52,642 - name:      weights_0

2025-01-31 18:44:58,742 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-31 18:44:58,742 - 0        8.116258   5.713142   0.254797   0.000000   0.822712   1.0e-04 , 1.0e-05 
2025-01-31 18:52:02,611 - 1        6.473376   5.509117   0.280495   0.000043   0.825326   1.0e-04 , 1.0e-05 
2025-01-31 18:52:02,612 - > saved mIoU
2025-01-31 18:59:07,892 - 2        6.021115   5.196212   0.291782   0.001071   0.827402   1.0e-04 , 1.0e-05 
2025-01-31 18:59:07,892 - > saved mIoU
2025-01-31 19:06:13,418 - 3        5.710937   5.254347   0.314819   0.002365   0.838166   1.0e-04 , 1.0e-05 
2025-01-31 19:06:13,419 - > saved mIoU
2025-01-31 19:13:18,016 - 4        5.408851   5.000132   0.320238   0.003742   0.838124   1.0e-04 , 1.0e-05 
2025-01-31 19:13:18,016 - > saved mIoU
2025-01-31 19:20:22,785 - 5        5.263149   5.008239   0.332127   0.007867   0.843813   1.0e-04 , 1.0e-05 
2025-01-31 19:20:22,785 - > saved mIoU
2025-01-31 19:27:27,248 - 6        5.135479   4.922296   0.342391   0.009690   0.849380   1.0e-04 , 1.0e-05 
2025-01-31 19:27:27,249 - > saved mIoU
2025-01-31 19:34:31,686 - 7        4.928433   4.943803   0.343459   0.010501   0.844846   1.0e-04 , 1.0e-05 
2025-01-31 19:34:31,687 - > saved mIoU
2025-01-31 19:41:36,199 - 8        4.917490   5.059237   0.344087   0.010475   0.836781   1.0e-04 , 1.0e-05 
2025-01-31 19:41:36,200 - > saved mIoU
2025-01-31 19:48:41,048 - 9        4.772964   5.044756   0.346719   0.010761   0.843066   1.0e-04 , 1.0e-05 
2025-01-31 19:48:41,048 - > saved mIoU
2025-01-31 19:55:45,424 - 10       4.643859   5.024278   0.351079   0.013388   0.845619   1.0e-04 , 1.0e-05 
2025-01-31 19:55:45,424 - > saved mIoU
2025-01-31 20:02:50,337 - 11       4.579231   5.045521   0.347462   0.014514   0.837975   1.0e-04 , 1.0e-05 
2025-01-31 20:09:53,727 - 12       4.469305   4.985176   0.351203   0.015609   0.845372   1.0e-04 , 1.0e-05 
2025-01-31 20:09:53,727 - > saved mIoU
2025-01-31 20:16:57,952 - 13       4.396685   4.885381   0.355733   0.022111   0.846220   5.0e-05 , 5.0e-06 
2025-01-31 20:16:57,952 - > saved mIoU
2025-01-31 20:24:01,923 - 14       4.317564   4.995424   0.358754   0.024761   0.842871   5.0e-05 , 5.0e-06 
2025-01-31 20:24:01,924 - > saved mIoU
2025-01-31 20:24:02,453 - Fine del training

2025-01-31 20:24:02,721 - 
Caricati i pesi in: /raid/homespace/piecestola/space/ML4CV/results/train_6/ckpts/weights_mIoU_0.pt

2025-01-31 20:24:02,723 - Inizio del training
2025-01-31 20:24:02,723 - optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 5e-05
    maximize: False
    weight_decay: 0.0001

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 5e-06
    maximize: False
    weight_decay: 0.0001
)
2025-01-31 20:24:02,723 - loss:      ArcFaceLoss(
  (loss): CrossEntropyLoss()
)
2025-01-31 20:24:02,723 - epochs:    50
2025-01-31 20:24:02,723 - name:      weights_1

2025-01-31 20:42:56,741 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-31 20:42:56,741 - 0        3.652126   4.205850   0.395201   0.044798   0.885029   5.0e-05 , 5.0e-06 
2025-01-31 21:01:51,563 - 1        2.829103   3.863401   0.416977   0.026088   0.891516   5.0e-05 , 5.0e-06 
2025-01-31 21:01:51,563 - > saved mIoU
2025-01-31 21:20:47,895 - 2        2.475914   3.660384   0.433537   0.028662   0.904053   5.0e-05 , 5.0e-06 
2025-01-31 21:20:47,895 - > saved mIoU
2025-01-31 21:39:43,992 - 3        2.252311   3.743041   0.419560   0.016797   0.898295   5.0e-05 , 5.0e-06 
2025-01-31 21:39:43,992 - > saved minIoU
2025-01-31 21:58:39,447 - 4        2.029276   3.514619   0.454268   0.028103   0.910552   5.0e-05 , 5.0e-06 
2025-01-31 21:58:39,448 - > saved mIoU
2025-01-31 22:17:35,081 - 5        1.860841   3.515999   0.459969   0.044073   0.914712   5.0e-05 , 5.0e-06 
2025-01-31 22:17:35,082 - > saved mIoU
2025-01-31 22:36:30,903 - 6        1.777626   3.447486   0.473203   0.091389   0.908896   5.0e-05 , 5.0e-06 
2025-01-31 22:36:30,903 - > saved mIoU
2025-01-31 22:55:26,280 - 7        1.648394   3.514837   0.491123   0.136383   0.904056   5.0e-05 , 5.0e-06 
2025-01-31 22:55:26,280 - > saved mIoU
2025-01-31 23:14:22,108 - 8        1.572866   3.328124   0.505205   0.179424   0.914260   5.0e-05 , 5.0e-06 
2025-01-31 23:14:22,109 - > saved mIoU
2025-01-31 23:33:17,564 - 9        1.534734   3.530754   0.502391   0.195089   0.900900   5.0e-05 , 5.0e-06 
2025-01-31 23:52:11,554 - 10       1.436491   3.334234   0.530680   0.222494   0.906821   5.0e-05 , 5.0e-06 
2025-01-31 23:52:11,555 - > saved mIoU
2025-02-01 00:11:07,627 - 11       1.390980   3.348678   0.533372   0.226730   0.905798   5.0e-05 , 5.0e-06 
2025-02-01 00:11:07,627 - > saved mIoU
2025-02-01 00:30:04,438 - 12       1.345822   3.338242   0.532324   0.224852   0.915966   5.0e-05 , 5.0e-06 
2025-02-01 00:48:58,255 - 13       1.315642   3.265940   0.548399   0.258765   0.920390   5.0e-05 , 5.0e-06 
2025-02-01 00:48:58,256 - > saved mIoU
2025-02-01 01:07:54,654 - 14       1.277119   3.392809   0.526980   0.233420   0.901437   5.0e-05 , 5.0e-06 
2025-02-01 01:26:49,752 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-02-01 01:26:49,752 - 15       1.253714   3.192247   0.554258   0.244448   0.903596   5.0e-05 , 5.0e-06 
2025-02-01 01:26:49,752 - > saved mIoU
2025-02-01 01:45:45,944 - 16       1.237559   3.079576   0.570796   0.268973   0.923077   5.0e-05 , 5.0e-06 
2025-02-01 01:45:45,944 - > saved mIoU
2025-02-01 02:04:42,685 - 17       1.225203   3.192543   0.567792   0.270471   0.916771   5.0e-05 , 5.0e-06 
2025-02-01 02:23:37,252 - 18       1.181368   3.114366   0.568073   0.281579   0.923264   5.0e-05 , 5.0e-06 
2025-02-01 02:42:31,285 - 19       1.158542   3.153489   0.554492   0.271731   0.918746   5.0e-05 , 5.0e-06 
2025-02-01 03:01:25,614 - 20       1.131319   3.072759   0.572643   0.287257   0.927020   5.0e-05 , 5.0e-06 
2025-02-01 03:01:25,615 - > saved mIoU
2025-02-01 03:20:22,743 - 21       1.118658   3.098352   0.569091   0.305687   0.922655   5.0e-05 , 5.0e-06 
2025-02-01 03:39:17,067 - 22       1.100991   3.030439   0.583023   0.291235   0.924557   5.0e-05 , 5.0e-06 
2025-02-01 03:39:17,068 - > saved mIoU
2025-02-01 03:58:13,395 - 23       1.093887   3.143999   0.566764   0.284267   0.924108   5.0e-05 , 5.0e-06 
2025-02-01 04:17:06,083 - 24       1.085250   3.041921   0.582141   0.290072   0.919053   5.0e-05 , 5.0e-06 
2025-02-01 04:35:59,377 - 25       1.074450   3.223049   0.573477   0.262884   0.925529   5.0e-05 , 5.0e-06 
2025-02-01 04:54:50,216 - 26       1.067607   2.946394   0.582765   0.312571   0.927777   5.0e-05 , 5.0e-06 
2025-02-01 05:13:39,870 - 27       1.040155   2.948769   0.587098   0.297440   0.923738   5.0e-05 , 5.0e-06 
2025-02-01 05:13:39,870 - > saved mIoU
2025-02-01 05:32:31,260 - 28       1.033453   2.972109   0.583578   0.307771   0.925570   5.0e-05 , 5.0e-06 
2025-02-01 05:51:20,998 - 29       1.014463   3.062699   0.565843   0.260741   0.932597   5.0e-05 , 5.0e-06 
2025-02-01 06:10:11,062 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-02-01 06:10:11,062 - 30       1.007148   2.924575   0.581368   0.299079   0.930837   5.0e-05 , 5.0e-06 
2025-02-01 06:28:58,335 - 31       1.014801   2.944212   0.571327   0.264638   0.932404   5.0e-05 , 5.0e-06 
2025-02-01 06:47:44,424 - 32       0.991303   2.900023   0.592545   0.300191   0.933736   5.0e-05 , 5.0e-06 
2025-02-01 06:47:44,424 - > saved mIoU
2025-02-01 07:06:32,017 - 33       0.995384   2.928270   0.587021   0.301539   0.928288   5.0e-05 , 5.0e-06 
2025-02-01 07:25:17,815 - 34       0.983332   3.057452   0.575657   0.280526   0.927138   5.0e-05 , 5.0e-06 
2025-02-01 07:44:02,730 - 35       0.972628   3.083487   0.567980   0.275756   0.924524   5.0e-05 , 5.0e-06 
2025-02-01 08:02:47,520 - 36       0.981024   2.936256   0.581517   0.276970   0.931196   5.0e-05 , 5.0e-06 
2025-02-01 08:21:31,743 - 37       0.960839   3.101294   0.572384   0.261634   0.930632   5.0e-05 , 5.0e-06 
2025-02-01 08:40:16,913 - 38       0.949207   3.070020   0.576507   0.272477   0.926494   5.0e-05 , 5.0e-06 
2025-02-01 08:59:02,171 - 39       0.940474   3.050302   0.586804   0.311642   0.931113   2.5e-05 , 2.5e-06 
2025-02-01 09:17:46,580 - 40       0.929140   2.975093   0.592141   0.290769   0.934649   2.5e-05 , 2.5e-06 
2025-02-01 09:36:32,107 - 41       0.918529   3.016080   0.587693   0.313360   0.929582   2.5e-05 , 2.5e-06 
2025-02-01 09:55:17,493 - 42       0.916459   2.969804   0.588405   0.293801   0.931610   2.5e-05 , 2.5e-06 
2025-02-01 10:14:02,087 - 43       0.909156   2.949955   0.591035   0.314943   0.934589   2.5e-05 , 2.5e-06 
2025-02-01 10:32:47,229 - 44       0.903795   2.910969   0.598193   0.303293   0.934409   2.5e-05 , 2.5e-06 
2025-02-01 10:32:47,229 - > saved mIoU
2025-02-01 10:51:34,370 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-02-01 10:51:34,370 - 45       0.905125   2.957829   0.591403   0.317584   0.932568   1.3e-05 , 1.3e-06 
2025-02-01 11:10:20,542 - 46       0.893874   2.960537   0.586011   0.293646   0.932722   1.3e-05 , 1.3e-06 
2025-02-01 11:29:03,172 - 47       0.893396   2.974743   0.591177   0.318409   0.933234   1.3e-05 , 1.3e-06 
2025-02-01 11:47:44,576 - 48       0.888366   2.975416   0.596718   0.311423   0.933919   1.3e-05 , 1.3e-06 
2025-02-01 12:06:26,477 - 49       0.889140   3.011151   0.592386   0.316084   0.932821   1.3e-05 , 1.3e-06 
2025-02-01 12:06:26,477 - Fine del training

