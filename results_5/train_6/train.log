2025-01-08 21:02:17,524 - device          : cuda:7
2025-01-08 21:02:17,524 - model           : resnet101
2025-01-08 21:02:17,524 - mlp             : 2
2025-01-08 21:02:17,524 - vae             : False
2025-01-08 21:02:17,524 - epochs          : 50
2025-01-08 21:02:17,525 - batch           : 16
2025-01-08 21:02:17,525 - lr              : 0.0001
2025-01-08 21:02:17,525 - crop            : 512
2025-01-08 21:02:17,525 - optimizer       : adam
2025-01-08 21:02:17,525 - biases          : False
2025-01-08 21:02:17,525 - focal_loss      : 0
2025-01-08 21:02:17,525 - activation      : softmax
2025-01-08 21:02:17,525 - class_weights   : False
2025-01-08 21:02:17,525 - norm_weights    : False
2025-01-08 21:02:17,525 - p               : 0.5
2025-01-08 21:02:17,540 - Dataset Creati
2025-01-08 21:02:17,540 - Training images: 5125
2025-01-08 21:02:17,540 - Validation images: 1031

2025-01-08 21:02:17,541 - Dataloader Creati
2025-01-08 21:02:17,541 - Training batches: 320
2025-01-08 21:02:17,541 - Validation batches: 128

2025-01-08 21:02:21,781 - Model: deeplabv3plus_resnet101

2025-01-08 21:02:21,856 - Modello caricato correttamente su cuda:7

2025-01-08 21:02:21,859 - Inizio del training
2025-01-08 21:02:21,860 - optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 1e-05
    maximize: False
    weight_decay: 0.0001
)
2025-01-08 21:02:21,860 - loss:      CrossEntropyLoss()
2025-01-08 21:02:21,860 - epochs:    15
2025-01-08 21:02:21,860 - name:      weights_0

2025-01-08 21:08:55,708 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-08 21:08:55,708 - 0        1.237760   0.655207   0.246422   0.000000   0.818751   1.0e-04 , 1.0e-05 
2025-01-08 21:15:29,542 - 1        0.853036   0.609389   0.266880   0.000000   0.824074   1.0e-04 , 1.0e-05 
2025-01-08 21:15:29,543 - > saved mIoU
2025-01-08 21:22:03,917 - 2        0.755339   0.588623   0.278284   0.000000   0.831921   1.0e-04 , 1.0e-05 
2025-01-08 21:22:03,918 - > saved mIoU
2025-01-08 21:28:39,385 - 3        0.711570   0.569172   0.294074   0.000000   0.834042   1.0e-04 , 1.0e-05 
2025-01-08 21:28:39,386 - > saved mIoU
2025-01-08 21:35:12,857 - 4        0.674270   0.563204   0.311536   0.000000   0.833357   1.0e-04 , 1.0e-05 
2025-01-08 21:35:12,857 - > saved mIoU
2025-01-08 21:41:48,053 - 5        0.654122   0.561229   0.330697   0.000000   0.842555   1.0e-04 , 1.0e-05 
2025-01-08 21:41:48,053 - > saved mIoU
2025-01-08 21:48:21,387 - 6        0.619428   0.557945   0.336734   0.000000   0.841733   1.0e-04 , 1.0e-05 
2025-01-08 21:48:21,388 - > saved mIoU
2025-01-08 21:54:55,712 - 7        0.610723   0.552296   0.346190   0.000000   0.848179   1.0e-04 , 1.0e-05 
2025-01-08 21:54:55,712 - > saved mIoU
2025-01-08 22:01:30,033 - 8        0.584703   0.549518   0.350022   0.000000   0.848785   1.0e-04 , 1.0e-05 
2025-01-08 22:01:30,034 - > saved mIoU
2025-01-08 22:08:04,595 - 9        0.568662   0.558440   0.352107   0.000000   0.843927   1.0e-04 , 1.0e-05 
2025-01-08 22:08:04,595 - > saved mIoU
2025-01-08 22:14:37,928 - 10       0.555724   0.544484   0.353330   0.000000   0.845221   1.0e-04 , 1.0e-05 
2025-01-08 22:14:37,929 - > saved mIoU
2025-01-08 22:21:11,067 - 11       0.546051   0.551031   0.355964   0.000000   0.847244   1.0e-04 , 1.0e-05 
2025-01-08 22:21:11,068 - > saved mIoU
2025-01-08 22:27:44,333 - 12       0.533669   0.548595   0.358402   0.000000   0.844798   1.0e-04 , 1.0e-05 
2025-01-08 22:27:44,334 - > saved mIoU
2025-01-08 22:34:18,565 - 13       0.523464   0.543747   0.360108   0.000000   0.849715   1.0e-04 , 1.0e-05 
2025-01-08 22:34:18,566 - > saved mIoU
2025-01-08 22:40:52,032 - 14       0.513103   0.545253   0.364412   0.000000   0.844066   1.0e-04 , 1.0e-05 
2025-01-08 22:40:52,032 - > saved mIoU
2025-01-08 22:40:52,542 - Fine del training

2025-01-08 22:40:52,809 - 
Caricati i pesi in: /raid/homespace/piecestola/space/ML4CV/results/train_6/ckpts/weights_mIoU_0.pt

2025-01-08 22:40:52,810 - Inizio del training
2025-01-08 22:40:52,811 - optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 1e-05
    maximize: False
    weight_decay: 0.0001
)
2025-01-08 22:40:52,811 - loss:      CrossEntropyLoss()
2025-01-08 22:40:52,811 - epochs:    50
2025-01-08 22:40:52,811 - name:      weights_1

2025-01-08 22:56:59,115 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-08 22:56:59,116 - 0        0.450443   0.475904   0.404272   0.000000   0.893069   1.0e-04 , 1.0e-05 
2025-01-08 23:13:07,135 - 1        0.339239   0.387908   0.436947   0.000000   0.909068   1.0e-04 , 1.0e-05 
2025-01-08 23:13:07,136 - > saved mIoU
2025-01-08 23:29:15,134 - 2        0.280755   0.380316   0.458186   0.000000   0.922334   1.0e-04 , 1.0e-05 
2025-01-08 23:29:15,134 - > saved mIoU
2025-01-08 23:45:23,543 - 3        0.234173   0.381869   0.469491   0.000000   0.920373   1.0e-04 , 1.0e-05 
2025-01-08 23:45:23,543 - > saved mIoU
2025-01-09 00:01:32,063 - 4        0.205658   0.352197   0.500849   0.000000   0.927688   1.0e-04 , 1.0e-05 
2025-01-09 00:01:32,064 - > saved mIoU
2025-01-09 00:17:40,508 - 5        0.186049   0.361584   0.500549   0.000000   0.922584   1.0e-04 , 1.0e-05 
2025-01-09 00:33:47,346 - 6        0.169422   0.360510   0.513895   0.000000   0.929151   1.0e-04 , 1.0e-05 
2025-01-09 00:33:47,347 - > saved mIoU
2025-01-09 00:49:57,001 - 7        0.156780   0.375419   0.527138   0.000000   0.932745   1.0e-04 , 1.0e-05 
2025-01-09 00:49:57,002 - > saved mIoU
2025-01-09 01:06:08,229 - 8        0.146307   0.371117   0.523454   0.000000   0.925986   1.0e-04 , 1.0e-05 
2025-01-09 01:22:17,592 - 9        0.139913   0.393069   0.527423   0.000000   0.930422   1.0e-04 , 1.0e-05 
2025-01-09 01:22:17,592 - > saved mIoU
2025-01-09 01:38:25,369 - 10       0.133177   0.375961   0.549892   0.000000   0.929862   1.0e-04 , 1.0e-05 
2025-01-09 01:38:25,369 - > saved mIoU
2025-01-09 01:54:33,515 - 11       0.130271   0.369220   0.549065   0.000000   0.928491   5.0e-05 , 5.0e-06 
2025-01-09 02:10:41,828 - 12       0.127736   0.368490   0.556078   0.000000   0.931961   5.0e-05 , 5.0e-06 
2025-01-09 02:10:41,829 - > saved mIoU
2025-01-09 02:26:49,767 - 13       0.120433   0.366077   0.559462   0.000000   0.929805   5.0e-05 , 5.0e-06 
2025-01-09 02:26:49,768 - > saved mIoU
2025-01-09 02:42:58,542 - 14       0.114980   0.365715   0.569152   0.000000   0.929384   5.0e-05 , 5.0e-06 
2025-01-09 02:42:58,542 - > saved mIoU
2025-01-09 02:59:07,364 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-09 02:59:07,364 - 15       0.112505   0.352166   0.567130   0.000000   0.929458   5.0e-05 , 5.0e-06 
2025-01-09 03:15:13,076 - 16       0.109284   0.363933   0.575689   0.000000   0.934591   5.0e-05 , 5.0e-06 
2025-01-09 03:15:13,077 - > saved mIoU
2025-01-09 03:31:21,197 - 17       0.108682   0.393852   0.569531   0.000000   0.927341   2.5e-05 , 2.5e-06 
2025-01-09 03:47:29,062 - 18       0.105982   0.385845   0.571441   0.000000   0.927647   2.5e-05 , 2.5e-06 
2025-01-09 04:03:35,375 - 19       0.103827   0.384586   0.576906   0.000000   0.930142   2.5e-05 , 2.5e-06 
2025-01-09 04:03:35,375 - > saved mIoU
2025-01-09 04:19:44,133 - 20       0.101624   0.384818   0.572264   0.000000   0.929337   2.5e-05 , 2.5e-06 
2025-01-09 04:35:52,361 - 21       0.100235   0.381189   0.569662   0.000000   0.930132   2.5e-05 , 2.5e-06 
2025-01-09 04:52:00,662 - 22       0.097720   0.396963   0.578845   0.000000   0.935790   2.5e-05 , 2.5e-06 
2025-01-09 04:52:00,662 - > saved mIoU
2025-01-09 05:08:10,940 - 23       0.098065   0.395693   0.574858   0.000000   0.935041   1.3e-05 , 1.3e-06 
2025-01-09 05:24:20,016 - 24       0.096192   0.398812   0.576764   0.000000   0.936245   1.3e-05 , 1.3e-06 
2025-01-09 05:40:28,989 - 25       0.094946   0.406292   0.577912   0.000000   0.935302   1.3e-05 , 1.3e-06 
2025-01-09 05:56:38,242 - 26       0.094932   0.405450   0.579835   0.000000   0.935131   1.3e-05 , 1.3e-06 
2025-01-09 05:56:38,242 - > saved mIoU
2025-01-09 06:12:48,478 - 27       0.093056   0.401830   0.578907   0.000000   0.933894   1.3e-05 , 1.3e-06 
2025-01-09 06:28:54,801 - 28       0.093359   0.411020   0.576037   0.000000   0.936073   1.3e-05 , 1.3e-06 
2025-01-09 06:45:02,350 - 29       0.092739   0.406300   0.579732   0.000000   0.936628   6.3e-06 , 6.3e-07 
2025-01-09 07:01:09,086 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-09 07:01:09,086 - 30       0.091287   0.412819   0.579861   0.000000   0.935564   6.3e-06 , 6.3e-07 
2025-01-09 07:01:09,086 - > saved mIoU
2025-01-09 07:17:17,434 - 31       0.090536   0.406473   0.579385   0.000000   0.934869   6.3e-06 , 6.3e-07 
2025-01-09 07:33:24,101 - 32       0.090556   0.406714   0.581793   0.000000   0.935050   6.3e-06 , 6.3e-07 
2025-01-09 07:33:24,101 - > saved mIoU
2025-01-09 07:49:34,150 - 33       0.089475   0.406835   0.580687   0.000000   0.936541   6.3e-06 , 6.3e-07 
2025-01-09 08:05:41,622 - 34       0.089817   0.405729   0.581883   0.000000   0.935495   6.3e-06 , 6.3e-07 
2025-01-09 08:05:41,623 - > saved mIoU
2025-01-09 08:21:50,706 - 35       0.089048   0.404471   0.583068   0.000000   0.937097   3.1e-06 , 3.1e-07 
2025-01-09 08:21:50,706 - > saved mIoU
2025-01-09 08:37:59,782 - 36       0.089250   0.409539   0.581432   0.000000   0.936222   3.1e-06 , 3.1e-07 
2025-01-09 08:54:06,902 - 37       0.088082   0.406248   0.583091   0.000000   0.937414   3.1e-06 , 3.1e-07 
2025-01-09 08:54:06,903 - > saved mIoU
2025-01-09 09:10:14,720 - 38       0.088102   0.407129   0.582233   0.000000   0.936563   3.1e-06 , 3.1e-07 
2025-01-09 09:26:23,415 - 39       0.087721   0.404816   0.584785   0.000000   0.937124   3.1e-06 , 3.1e-07 
2025-01-09 09:26:23,415 - > saved mIoU
2025-01-09 09:42:33,655 - 40       0.087694   0.412529   0.581500   0.000000   0.936253   3.1e-06 , 3.1e-07 
2025-01-09 09:58:40,302 - 41       0.087134   0.407894   0.581851   0.000000   0.937237   1.6e-06 , 1.6e-07 
2025-01-09 10:14:48,946 - 42       0.087866   0.406368   0.582347   0.000000   0.936589   1.6e-06 , 1.6e-07 
2025-01-09 10:30:57,011 - 43       0.086391   0.407646   0.581925   0.000000   0.936975   1.6e-06 , 1.6e-07 
2025-01-09 10:47:03,916 - 44       0.087421   0.408468   0.581435   0.000000   0.936964   1.6e-06 , 1.6e-07 
2025-01-09 11:03:11,921 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-09 11:03:11,922 - 45       0.086751   0.408199   0.582052   0.000000   0.936622   1.6e-06 , 1.6e-07 
2025-01-09 11:19:20,308 - 46       0.086368   0.409588   0.581424   0.000000   0.936909   1.6e-06 , 1.6e-07 
2025-01-09 11:35:28,600 - 47       0.085781   0.409336   0.580858   0.000000   0.935748   7.8e-07 , 7.8e-08 
2025-01-09 11:51:36,925 - 48       0.086495   0.410224   0.581680   0.000000   0.937301   7.8e-07 , 7.8e-08 
2025-01-09 12:07:43,365 - 49       0.086216   0.407712   0.581516   0.000000   0.936737   7.8e-07 , 7.8e-08 
2025-01-09 12:07:43,366 - Fine del training

