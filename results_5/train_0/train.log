2025-01-08 21:01:48,471 - device          : cuda:0
2025-01-08 21:01:48,471 - model           : resnet101
2025-01-08 21:01:48,471 - mlp             : 0
2025-01-08 21:01:48,471 - vae             : False
2025-01-08 21:01:48,471 - epochs          : 50
2025-01-08 21:01:48,472 - batch           : 16
2025-01-08 21:01:48,472 - lr              : 0.001
2025-01-08 21:01:48,472 - crop            : 512
2025-01-08 21:01:48,472 - optimizer       : adam
2025-01-08 21:01:48,472 - biases          : False
2025-01-08 21:01:48,472 - focal_loss      : 0
2025-01-08 21:01:48,472 - activation      : softmax
2025-01-08 21:01:48,472 - class_weights   : False
2025-01-08 21:01:48,472 - norm_weights    : False
2025-01-08 21:01:48,472 - p               : 0.3
2025-01-08 21:01:48,480 - Dataset Creati
2025-01-08 21:01:48,480 - Training images: 5125
2025-01-08 21:01:48,480 - Validation images: 1031

2025-01-08 21:01:48,480 - Dataloader Creati
2025-01-08 21:01:48,480 - Training batches: 320
2025-01-08 21:01:48,480 - Validation batches: 128

2025-01-08 21:01:52,041 - Model: deeplabv3plus_resnet101

2025-01-08 21:01:52,104 - Modello caricato correttamente su cuda:0

2025-01-08 21:01:52,106 - Inizio del training
2025-01-08 21:01:52,106 - optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 0.001
    maximize: False
    weight_decay: 0.0001

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001
)
2025-01-08 21:01:52,107 - loss:      CrossEntropyLoss()
2025-01-08 21:01:52,107 - epochs:    15
2025-01-08 21:01:52,107 - name:      weights_0

2025-01-08 21:08:15,500 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-08 21:08:15,500 - 0        0.729510   0.692386   0.331523   0.000000   0.816390   1.0e-03 , 1.0e-04 
2025-01-08 21:14:39,607 - 1        0.602634   0.639423   0.344642   0.000000   0.827191   1.0e-03 , 1.0e-04 
2025-01-08 21:14:39,608 - > saved mIoU
2025-01-08 21:21:04,513 - 2        0.562908   0.649567   0.354670   0.001441   0.818294   1.0e-03 , 1.0e-04 
2025-01-08 21:21:04,513 - > saved mIoU
2025-01-08 21:27:30,087 - 3        0.528785   0.631782   0.379486   0.003501   0.832204   1.0e-03 , 1.0e-04 
2025-01-08 21:27:30,087 - > saved mIoU
2025-01-08 21:33:54,262 - 4        0.521415   0.619486   0.389985   0.006732   0.835198   1.0e-03 , 1.0e-04 
2025-01-08 21:33:54,262 - > saved mIoU
2025-01-08 21:40:18,464 - 5        0.511011   0.642486   0.390274   0.007023   0.824012   1.0e-03 , 1.0e-04 
2025-01-08 21:40:18,465 - > saved mIoU
2025-01-08 21:46:43,181 - 6        0.495305   0.640038   0.387692   0.014650   0.827804   1.0e-03 , 1.0e-04 
2025-01-08 21:53:06,204 - 7        0.487324   0.628319   0.391535   0.014002   0.833699   1.0e-03 , 1.0e-04 
2025-01-08 21:53:06,204 - > saved mIoU
2025-01-08 21:59:29,863 - 8        0.484769   0.636879   0.399094   0.022522   0.832414   1.0e-03 , 1.0e-04 
2025-01-08 21:59:29,864 - > saved mIoU
2025-01-08 22:05:55,920 - 9        0.474435   0.642326   0.397233   0.014839   0.836932   1.0e-03 , 1.0e-04 
2025-01-08 22:12:19,633 - 10       0.470250   0.647962   0.403154   0.028585   0.835186   1.0e-03 , 1.0e-04 
2025-01-08 22:12:19,633 - > saved mIoU
2025-01-08 22:18:42,603 - 11       0.458125   0.637576   0.401400   0.034056   0.844728   5.0e-04 , 5.0e-05 
2025-01-08 22:25:05,002 - 12       0.439778   0.651282   0.400818   0.041686   0.839547   5.0e-04 , 5.0e-05 
2025-01-08 22:31:27,681 - 13       0.428369   0.640029   0.406307   0.036686   0.846902   5.0e-04 , 5.0e-05 
2025-01-08 22:31:27,681 - > saved mIoU
2025-01-08 22:37:50,525 - 14       0.432661   0.659937   0.404444   0.038150   0.842995   5.0e-04 , 5.0e-05 
2025-01-08 22:37:50,526 - Fine del training

2025-01-08 22:37:50,825 - 
Caricati i pesi in: /raid/homespace/piecestola/space/ML4CV/results/train_0/ckpts/weights_mIoU_0.pt

2025-01-08 22:37:50,826 - Inizio del training
2025-01-08 22:37:50,826 - optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 0.0005
    maximize: False
    weight_decay: 0.0001

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 5e-05
    maximize: False
    weight_decay: 0.0001
)
2025-01-08 22:37:50,826 - loss:      CrossEntropyLoss()
2025-01-08 22:37:50,826 - epochs:    50
2025-01-08 22:37:50,826 - name:      weights_1

2025-01-08 22:53:52,451 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-08 22:53:52,451 - 0        0.434674   0.719265   0.368365   0.003023   0.833345   5.0e-04 , 5.0e-05 
2025-01-08 23:09:52,487 - 1        0.315380   0.537228   0.433899   0.029453   0.849086   5.0e-04 , 5.0e-05 
2025-01-08 23:09:52,488 - > saved mIoU
2025-01-08 23:25:54,255 - 2        0.239383   0.528552   0.438355   0.069534   0.861550   5.0e-04 , 5.0e-05 
2025-01-08 23:25:54,255 - > saved mIoU
2025-01-08 23:41:56,335 - 3        0.190587   0.452076   0.452700   0.084703   0.902902   5.0e-04 , 5.0e-05 
2025-01-08 23:41:56,336 - > saved mIoU
2025-01-08 23:57:58,367 - 4        0.157370   0.479350   0.483447   0.074982   0.905917   5.0e-04 , 5.0e-05 
2025-01-08 23:57:58,367 - > saved mIoU
2025-01-09 00:14:03,224 - 5        0.137034   0.452008   0.485704   0.070769   0.903987   5.0e-04 , 5.0e-05 
2025-01-09 00:14:03,225 - > saved mIoU
2025-01-09 00:30:04,705 - 6        0.122285   0.469774   0.484208   0.059929   0.912078   5.0e-04 , 5.0e-05 
2025-01-09 00:46:05,141 - 7        0.124811   0.452771   0.534483   0.136634   0.906992   5.0e-04 , 5.0e-05 
2025-01-09 00:46:05,142 - > saved mIoU
2025-01-09 01:02:11,741 - 8        0.129267   0.486607   0.515781   0.122769   0.912288   5.0e-04 , 5.0e-05 
2025-01-09 01:18:15,471 - 9        0.136767   0.700694   0.467643   0.021204   0.860330   5.0e-04 , 5.0e-05 
2025-01-09 01:34:19,942 - 10       0.146088   0.496594   0.522268   0.091425   0.899137   5.0e-04 , 5.0e-05 
2025-01-09 01:50:20,610 - 11       0.109464   0.505934   0.534813   0.167105   0.896759   5.0e-04 , 5.0e-05 
2025-01-09 01:50:20,610 - > saved mIoU
2025-01-09 02:06:21,069 - 12       0.101114   0.442498   0.553281   0.206839   0.912970   2.5e-04 , 2.5e-05 
2025-01-09 02:06:21,069 - > saved mIoU
2025-01-09 02:22:21,606 - 13       0.092632   0.444051   0.561963   0.228038   0.922084   2.5e-04 , 2.5e-05 
2025-01-09 02:22:21,606 - > saved mIoU
2025-01-09 02:38:23,213 - 14       0.086841   0.431333   0.563801   0.250201   0.920708   2.5e-04 , 2.5e-05 
2025-01-09 02:38:23,213 - > saved mIoU
2025-01-09 02:54:25,194 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-09 02:54:25,194 - 15       0.084895   0.461906   0.544814   0.208859   0.923168   2.5e-04 , 2.5e-05 
2025-01-09 03:10:25,704 - 16       0.081474   0.438714   0.560112   0.248387   0.916185   2.5e-04 , 2.5e-05 
2025-01-09 03:26:26,521 - 17       0.080021   0.432197   0.569004   0.174662   0.931578   2.5e-04 , 2.5e-05 
2025-01-09 03:26:26,522 - > saved mIoU
2025-01-09 03:42:30,702 - 18       0.077388   0.453828   0.576011   0.190331   0.926207   2.5e-04 , 2.5e-05 
2025-01-09 03:42:30,702 - > saved mIoU
2025-01-09 03:58:33,491 - 19       0.075567   0.473375   0.569063   0.172067   0.931489   2.5e-04 , 2.5e-05 
2025-01-09 04:14:35,584 - 20       0.074917   0.495910   0.528870   0.230284   0.907699   2.5e-04 , 2.5e-05 
2025-01-09 04:30:36,486 - 21       0.076084   0.448060   0.578444   0.274284   0.918731   1.3e-04 , 1.3e-05 
2025-01-09 04:30:36,487 - > saved mIoU
2025-01-09 04:46:39,320 - 22       0.072047   0.444374   0.583190   0.263010   0.929331   1.3e-04 , 1.3e-05 
2025-01-09 04:46:39,321 - > saved mIoU
2025-01-09 05:02:45,764 - 23       0.069634   0.440831   0.584767   0.245653   0.926266   1.3e-04 , 1.3e-05 
2025-01-09 05:02:45,764 - > saved mIoU
2025-01-09 05:18:50,396 - 24       0.067642   0.417537   0.589157   0.272476   0.930304   1.3e-04 , 1.3e-05 
2025-01-09 05:18:50,396 - > saved mIoU
2025-01-09 05:34:54,262 - 25       0.067326   0.450933   0.579903   0.262041   0.926072   1.3e-04 , 1.3e-05 
2025-01-09 05:50:56,685 - 26       0.067383   0.443699   0.578940   0.220639   0.931689   1.3e-04 , 1.3e-05 
2025-01-09 06:06:59,895 - 27       0.066843   0.473391   0.579082   0.129272   0.924877   1.3e-04 , 1.3e-05 
2025-01-09 06:23:01,511 - 28       0.066551   0.451751   0.588523   0.221195   0.929031   1.3e-04 , 1.3e-05 
2025-01-09 06:39:02,776 - 29       0.066759   0.495111   0.567128   0.179180   0.935901   1.3e-04 , 1.3e-05 
2025-01-09 06:55:03,165 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-09 06:55:03,165 - 30       0.065494   0.461656   0.594837   0.223441   0.936260   1.3e-04 , 1.3e-05 
2025-01-09 06:55:03,165 - > saved mIoU
2025-01-09 07:11:04,790 - 31       0.065290   0.434647   0.612387   0.267295   0.936805   6.3e-05 , 6.3e-06 
2025-01-09 07:11:04,790 - > saved mIoU
2025-01-09 07:27:07,664 - 32       0.064545   0.452501   0.616568   0.239951   0.938321   6.3e-05 , 6.3e-06 
2025-01-09 07:27:07,664 - > saved mIoU
2025-01-09 07:43:09,884 - 33       0.061817   0.455894   0.612722   0.251717   0.938134   6.3e-05 , 6.3e-06 
2025-01-09 07:59:11,200 - 34       0.061407   0.461312   0.611000   0.233104   0.938549   6.3e-05 , 6.3e-06 
2025-01-09 08:15:11,982 - 35       0.060290   0.454581   0.610038   0.225654   0.938879   6.3e-05 , 6.3e-06 
2025-01-09 08:31:13,923 - 36       0.060079   0.460888   0.602722   0.255836   0.938640   6.3e-05 , 6.3e-06 
2025-01-09 08:47:13,549 - 37       0.059976   0.458723   0.609635   0.246197   0.936593   3.1e-05 , 3.1e-06 
2025-01-09 09:03:14,360 - 38       0.059759   0.474974   0.608837   0.247059   0.938813   3.1e-05 , 3.1e-06 
2025-01-09 09:19:16,696 - 39       0.059753   0.461192   0.606659   0.245964   0.936842   3.1e-05 , 3.1e-06 
2025-01-09 09:35:17,618 - 40       0.058275   0.473893   0.610187   0.226328   0.940576   3.1e-05 , 3.1e-06 
2025-01-09 09:51:19,429 - 41       0.057536   0.459027   0.605066   0.255789   0.939520   3.1e-05 , 3.1e-06 
2025-01-09 10:07:22,657 - 42       0.057193   0.458989   0.615822   0.261249   0.940579   3.1e-05 , 3.1e-06 
2025-01-09 10:23:24,879 - 43       0.057623   0.465086   0.609868   0.238910   0.940009   1.6e-05 , 1.6e-06 
2025-01-09 10:39:25,958 - 44       0.057587   0.462972   0.610184   0.249506   0.939217   1.6e-05 , 1.6e-06 
2025-01-09 10:55:28,335 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-09 10:55:28,336 - 45       0.056890   0.465183   0.607890   0.252884   0.940195   1.6e-05 , 1.6e-06 
2025-01-09 11:11:30,877 - 46       0.056411   0.461682   0.610706   0.246362   0.939656   1.6e-05 , 1.6e-06 
2025-01-09 11:27:34,053 - 47       0.056240   0.452739   0.610794   0.248845   0.939942   1.6e-05 , 1.6e-06 
2025-01-09 11:43:34,580 - 48       0.055801   0.458190   0.611850   0.253500   0.941394   1.6e-05 , 1.6e-06 
2025-01-09 11:59:35,470 - 49       0.056000   0.464139   0.612589   0.234707   0.941881   7.8e-06 , 7.8e-07 
2025-01-09 11:59:35,471 - Fine del training

