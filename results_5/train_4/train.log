2025-01-08 21:02:08,487 - device          : cuda:5
2025-01-08 21:02:08,487 - model           : resnet101
2025-01-08 21:02:08,487 - mlp             : 2
2025-01-08 21:02:08,487 - vae             : False
2025-01-08 21:02:08,487 - epochs          : 50
2025-01-08 21:02:08,487 - batch           : 16
2025-01-08 21:02:08,487 - lr              : 0.0001
2025-01-08 21:02:08,488 - crop            : 512
2025-01-08 21:02:08,488 - optimizer       : adam
2025-01-08 21:02:08,488 - biases          : False
2025-01-08 21:02:08,488 - focal_loss      : 0
2025-01-08 21:02:08,488 - activation      : softmax
2025-01-08 21:02:08,488 - class_weights   : False
2025-01-08 21:02:08,488 - norm_weights    : False
2025-01-08 21:02:08,488 - p               : 0.3
2025-01-08 21:02:08,497 - Dataset Creati
2025-01-08 21:02:08,497 - Training images: 5125
2025-01-08 21:02:08,497 - Validation images: 1031

2025-01-08 21:02:08,498 - Dataloader Creati
2025-01-08 21:02:08,498 - Training batches: 320
2025-01-08 21:02:08,498 - Validation batches: 128

2025-01-08 21:02:12,736 - Model: deeplabv3plus_resnet101

2025-01-08 21:02:12,807 - Modello caricato correttamente su cuda:5

2025-01-08 21:02:12,810 - Inizio del training
2025-01-08 21:02:12,810 - optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 1e-05
    maximize: False
    weight_decay: 0.0001
)
2025-01-08 21:02:12,810 - loss:      CrossEntropyLoss()
2025-01-08 21:02:12,810 - epochs:    15
2025-01-08 21:02:12,810 - name:      weights_0

2025-01-08 21:08:47,054 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-08 21:08:47,055 - 0        1.119214   0.642842   0.249952   0.000000   0.814193   1.0e-04 , 1.0e-05 
2025-01-08 21:15:20,849 - 1        0.769468   0.605775   0.275387   0.000000   0.825609   1.0e-04 , 1.0e-05 
2025-01-08 21:15:20,850 - > saved mIoU
2025-01-08 21:21:54,196 - 2        0.683040   0.589333   0.301131   0.000000   0.836637   1.0e-04 , 1.0e-05 
2025-01-08 21:21:54,196 - > saved mIoU
2025-01-08 21:28:27,926 - 3        0.645602   0.571336   0.320752   0.000000   0.840575   1.0e-04 , 1.0e-05 
2025-01-08 21:28:27,926 - > saved mIoU
2025-01-08 21:35:00,057 - 4        0.612523   0.566344   0.331248   0.000000   0.838391   1.0e-04 , 1.0e-05 
2025-01-08 21:35:00,057 - > saved mIoU
2025-01-08 21:41:33,348 - 5        0.596103   0.564205   0.345138   0.000000   0.847038   1.0e-04 , 1.0e-05 
2025-01-08 21:41:33,348 - > saved mIoU
2025-01-08 21:48:06,467 - 6        0.565554   0.562275   0.347250   0.000000   0.844701   1.0e-04 , 1.0e-05 
2025-01-08 21:48:06,467 - > saved mIoU
2025-01-08 21:54:39,040 - 7        0.559579   0.557877   0.354922   0.000000   0.850471   1.0e-04 , 1.0e-05 
2025-01-08 21:54:39,041 - > saved mIoU
2025-01-08 22:01:12,551 - 8        0.536627   0.554445   0.359200   0.000000   0.850866   1.0e-04 , 1.0e-05 
2025-01-08 22:01:12,551 - > saved mIoU
2025-01-08 22:07:45,178 - 9        0.522290   0.563641   0.362302   0.000000   0.846590   1.0e-04 , 1.0e-05 
2025-01-08 22:07:45,178 - > saved mIoU
2025-01-08 22:14:17,628 - 10       0.511205   0.550219   0.364489   0.000000   0.847166   1.0e-04 , 1.0e-05 
2025-01-08 22:14:17,628 - > saved mIoU
2025-01-08 22:20:51,921 - 11       0.502437   0.556696   0.367034   0.000000   0.849128   1.0e-04 , 1.0e-05 
2025-01-08 22:20:51,921 - > saved mIoU
2025-01-08 22:27:24,094 - 12       0.491798   0.557118   0.370252   0.000000   0.845829   1.0e-04 , 1.0e-05 
2025-01-08 22:27:24,094 - > saved mIoU
2025-01-08 22:33:57,671 - 13       0.482159   0.550970   0.372237   0.000000   0.851501   1.0e-04 , 1.0e-05 
2025-01-08 22:33:57,671 - > saved mIoU
2025-01-08 22:40:31,033 - 14       0.472749   0.552884   0.376402   0.000000   0.845943   1.0e-04 , 1.0e-05 
2025-01-08 22:40:31,034 - > saved mIoU
2025-01-08 22:40:31,491 - Fine del training

2025-01-08 22:40:31,759 - 
Caricati i pesi in: /raid/homespace/piecestola/space/ML4CV/results/train_4/ckpts/weights_mIoU_0.pt

2025-01-08 22:40:31,769 - Inizio del training
2025-01-08 22:40:31,769 - optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 1e-05
    maximize: False
    weight_decay: 0.0001
)
2025-01-08 22:40:31,769 - loss:      CrossEntropyLoss()
2025-01-08 22:40:31,769 - epochs:    50
2025-01-08 22:40:31,769 - name:      weights_1

2025-01-08 22:56:38,464 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-08 22:56:38,465 - 0        0.416837   0.465796   0.420063   0.000000   0.897017   1.0e-04 , 1.0e-05 
2025-01-08 23:12:46,247 - 1        0.309030   0.395044   0.457826   0.000000   0.909247   1.0e-04 , 1.0e-05 
2025-01-08 23:12:46,247 - > saved mIoU
2025-01-08 23:28:53,949 - 2        0.252063   0.375851   0.479791   0.000000   0.923914   1.0e-04 , 1.0e-05 
2025-01-08 23:28:53,949 - > saved mIoU
2025-01-08 23:45:02,757 - 3        0.207603   0.364967   0.493258   0.000000   0.924460   1.0e-04 , 1.0e-05 
2025-01-08 23:45:02,758 - > saved mIoU
2025-01-09 00:01:11,802 - 4        0.181496   0.361461   0.512594   0.000000   0.925986   1.0e-04 , 1.0e-05 
2025-01-09 00:01:11,802 - > saved mIoU
2025-01-09 00:17:19,755 - 5        0.163454   0.374618   0.513713   0.000000   0.920142   1.0e-04 , 1.0e-05 
2025-01-09 00:17:19,755 - > saved mIoU
2025-01-09 00:33:29,066 - 6        0.150328   0.360422   0.534723   0.000000   0.931085   1.0e-04 , 1.0e-05 
2025-01-09 00:33:29,066 - > saved mIoU
2025-01-09 00:49:38,071 - 7        0.138973   0.370933   0.536511   0.000000   0.932885   1.0e-04 , 1.0e-05 
2025-01-09 00:49:38,071 - > saved mIoU
2025-01-09 01:05:49,207 - 8        0.130052   0.369981   0.528998   0.000000   0.928884   1.0e-04 , 1.0e-05 
2025-01-09 01:21:58,308 - 9        0.124805   0.404506   0.532946   0.003937   0.931010   1.0e-04 , 1.0e-05 
2025-01-09 01:38:06,897 - 10       0.117946   0.399791   0.562289   0.204305   0.931336   1.0e-04 , 1.0e-05 
2025-01-09 01:38:06,897 - > saved mIoU
2025-01-09 01:54:15,582 - 11       0.115082   0.403315   0.543128   0.038647   0.932957   1.0e-04 , 1.0e-05 
2025-01-09 02:10:23,449 - 12       0.130718   0.398086   0.507942   0.063562   0.903718   1.0e-04 , 1.0e-05 
2025-01-09 02:26:30,505 - 13       0.132298   0.383788   0.589706   0.286241   0.924144   5.0e-05 , 5.0e-06 
2025-01-09 02:26:30,506 - > saved mIoU
2025-01-09 02:42:40,602 - 14       0.111498   0.369641   0.600592   0.299000   0.924574   5.0e-05 , 5.0e-06 
2025-01-09 02:42:40,602 - > saved mIoU
2025-01-09 02:58:48,828 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-09 02:58:48,828 - 15       0.104867   0.370655   0.605125   0.300574   0.931629   5.0e-05 , 5.0e-06 
2025-01-09 02:58:48,828 - > saved mIoU
2025-01-09 03:14:58,191 - 16       0.100537   0.376067   0.608219   0.295447   0.934264   5.0e-05 , 5.0e-06 
2025-01-09 03:14:58,192 - > saved mIoU
2025-01-09 03:31:07,231 - 17       0.098305   0.369063   0.616805   0.296245   0.935060   5.0e-05 , 5.0e-06 
2025-01-09 03:31:07,232 - > saved mIoU
2025-01-09 03:47:15,308 - 18       0.096495   0.372032   0.616031   0.302103   0.934460   5.0e-05 , 5.0e-06 
2025-01-09 04:03:22,665 - 19       0.094936   0.391107   0.614541   0.315330   0.932873   2.5e-05 , 2.5e-06 
2025-01-09 04:19:30,319 - 20       0.092340   0.387964   0.617460   0.317415   0.931881   2.5e-05 , 2.5e-06 
2025-01-09 04:19:30,319 - > saved mIoU
2025-01-09 04:35:40,628 - 21       0.091091   0.386697   0.618091   0.308362   0.933565   2.5e-05 , 2.5e-06 
2025-01-09 04:35:40,628 - > saved mIoU
2025-01-09 04:51:50,890 - 22       0.088814   0.393101   0.622714   0.323568   0.935073   2.5e-05 , 2.5e-06 
2025-01-09 04:51:50,891 - > saved mIoU
2025-01-09 05:08:01,802 - 23       0.088510   0.393322   0.616755   0.304622   0.933528   2.5e-05 , 2.5e-06 
2025-01-09 05:24:11,021 - 24       0.087118   0.387332   0.616471   0.322550   0.934088   2.5e-05 , 2.5e-06 
2025-01-09 05:40:19,843 - 25       0.086509   0.408098   0.619618   0.309261   0.936240   1.3e-05 , 1.3e-06 
2025-01-09 05:56:28,807 - 26       0.085662   0.399871   0.624936   0.320444   0.934903   1.3e-05 , 1.3e-06 
2025-01-09 05:56:28,807 - > saved mIoU
2025-01-09 06:12:40,508 - 27       0.083965   0.394715   0.628571   0.312612   0.935020   1.3e-05 , 1.3e-06 
2025-01-09 06:12:40,509 - > saved mIoU
2025-01-09 06:28:50,518 - 28       0.084080   0.403117   0.622738   0.321307   0.935764   1.3e-05 , 1.3e-06 
2025-01-09 06:45:00,561 - 29       0.083333   0.403737   0.623000   0.318088   0.936748   1.3e-05 , 1.3e-06 
2025-01-09 07:01:07,961 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-09 07:01:07,961 - 30       0.082231   0.418070   0.622189   0.329116   0.936239   1.3e-05 , 1.3e-06 
2025-01-09 07:17:16,279 - 31       0.081415   0.405523   0.624872   0.325866   0.935175   6.3e-06 , 6.3e-07 
2025-01-09 07:33:24,868 - 32       0.081290   0.405214   0.627720   0.326154   0.934283   6.3e-06 , 6.3e-07 
2025-01-09 07:49:32,896 - 33       0.080227   0.404557   0.625573   0.328923   0.936074   6.3e-06 , 6.3e-07 
2025-01-09 08:05:41,733 - 34       0.080433   0.407045   0.625457   0.325376   0.935695   6.3e-06 , 6.3e-07 
2025-01-09 08:21:49,883 - 35       0.079603   0.406648   0.628686   0.326097   0.936873   6.3e-06 , 6.3e-07 
2025-01-09 08:21:49,883 - > saved mIoU
2025-01-09 08:37:59,530 - 36       0.079774   0.411282   0.626774   0.329636   0.935496   6.3e-06 , 6.3e-07 
2025-01-09 08:54:08,297 - 37       0.078763   0.406657   0.628270   0.332052   0.936620   3.1e-06 , 3.1e-07 
2025-01-09 09:10:15,679 - 38       0.078720   0.407051   0.628609   0.327907   0.935891   3.1e-06 , 3.1e-07 
2025-01-09 09:26:24,289 - 39       0.078333   0.403991   0.631311   0.327854   0.936566   3.1e-06 , 3.1e-07 
2025-01-09 09:26:24,289 - > saved mIoU
2025-01-09 09:42:34,197 - 40       0.078389   0.411882   0.628392   0.332284   0.936381   3.1e-06 , 3.1e-07 
2025-01-09 09:58:43,643 - 41       0.077723   0.409604   0.630159   0.334094   0.937135   3.1e-06 , 3.1e-07 
2025-01-09 10:14:52,959 - 42       0.078295   0.411211   0.628091   0.333548   0.935850   3.1e-06 , 3.1e-07 
2025-01-09 10:31:01,558 - 43       0.076929   0.407324   0.629187   0.331372   0.936199   1.6e-06 , 1.6e-07 
2025-01-09 10:47:12,549 - 44       0.077841   0.406771   0.628089   0.331854   0.936398   1.6e-06 , 1.6e-07 
2025-01-09 11:03:21,214 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-09 11:03:21,215 - 45       0.077301   0.407810   0.628174   0.330112   0.935623   1.6e-06 , 1.6e-07 
2025-01-09 11:19:29,634 - 46       0.077014   0.407801   0.628344   0.331323   0.936076   1.6e-06 , 1.6e-07 
2025-01-09 11:35:38,243 - 47       0.076439   0.410985   0.627979   0.331303   0.935523   1.6e-06 , 1.6e-07 
2025-01-09 11:51:46,645 - 48       0.076981   0.410229   0.628296   0.333897   0.936256   1.6e-06 , 1.6e-07 
2025-01-09 12:07:53,606 - 49       0.076747   0.408914   0.627485   0.334005   0.935956   7.8e-07 , 7.8e-08 
2025-01-09 12:07:53,607 - Fine del training

