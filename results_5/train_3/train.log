2025-01-08 21:02:03,681 - device          : cuda:4
2025-01-08 21:02:03,681 - model           : resnet101
2025-01-08 21:02:03,681 - mlp             : 2
2025-01-08 21:02:03,681 - vae             : False
2025-01-08 21:02:03,681 - epochs          : 50
2025-01-08 21:02:03,681 - batch           : 16
2025-01-08 21:02:03,681 - lr              : 0.0001
2025-01-08 21:02:03,681 - crop            : 512
2025-01-08 21:02:03,681 - optimizer       : adam
2025-01-08 21:02:03,681 - biases          : False
2025-01-08 21:02:03,682 - focal_loss      : 0
2025-01-08 21:02:03,682 - activation      : softmax
2025-01-08 21:02:03,682 - class_weights   : False
2025-01-08 21:02:03,682 - norm_weights    : False
2025-01-08 21:02:03,682 - p               : 0.2
2025-01-08 21:02:03,690 - Dataset Creati
2025-01-08 21:02:03,691 - Training images: 5125
2025-01-08 21:02:03,691 - Validation images: 1031

2025-01-08 21:02:03,691 - Dataloader Creati
2025-01-08 21:02:03,691 - Training batches: 320
2025-01-08 21:02:03,691 - Validation batches: 128

2025-01-08 21:02:07,739 - Model: deeplabv3plus_resnet101

2025-01-08 21:02:07,807 - Modello caricato correttamente su cuda:4

2025-01-08 21:02:07,810 - Inizio del training
2025-01-08 21:02:07,811 - optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 1e-05
    maximize: False
    weight_decay: 0.0001
)
2025-01-08 21:02:07,811 - loss:      CrossEntropyLoss()
2025-01-08 21:02:07,811 - epochs:    15
2025-01-08 21:02:07,811 - name:      weights_0

2025-01-08 21:08:41,250 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-08 21:08:41,251 - 0        1.081828   0.640948   0.250288   0.000000   0.813671   1.0e-04 , 1.0e-05 
2025-01-08 21:15:14,924 - 1        0.739337   0.606058   0.278545   0.000000   0.826277   1.0e-04 , 1.0e-05 
2025-01-08 21:15:14,925 - > saved mIoU
2025-01-08 21:21:48,610 - 2        0.655252   0.592726   0.309000   0.000000   0.838463   1.0e-04 , 1.0e-05 
2025-01-08 21:21:48,610 - > saved mIoU
2025-01-08 21:28:22,176 - 3        0.619580   0.576564   0.326528   0.000000   0.842206   1.0e-04 , 1.0e-05 
2025-01-08 21:28:22,176 - > saved mIoU
2025-01-08 21:34:55,083 - 4        0.587827   0.571797   0.334489   0.000000   0.839739   1.0e-04 , 1.0e-05 
2025-01-08 21:34:55,083 - > saved mIoU
2025-01-08 21:41:29,086 - 5        0.572417   0.570997   0.347760   0.000000   0.848589   1.0e-04 , 1.0e-05 
2025-01-08 21:41:29,087 - > saved mIoU
2025-01-08 21:48:01,682 - 6        0.543366   0.569419   0.350447   0.000000   0.845742   1.0e-04 , 1.0e-05 
2025-01-08 21:48:01,682 - > saved mIoU
2025-01-08 21:54:34,896 - 7        0.538138   0.564672   0.357743   0.000000   0.851613   1.0e-04 , 1.0e-05 
2025-01-08 21:54:34,897 - > saved mIoU
2025-01-08 22:01:09,432 - 8        0.516086   0.560883   0.362202   0.000000   0.851371   1.0e-04 , 1.0e-05 
2025-01-08 22:01:09,432 - > saved mIoU
2025-01-08 22:07:42,519 - 9        0.502339   0.570262   0.366130   0.000000   0.847365   1.0e-04 , 1.0e-05 
2025-01-08 22:07:42,519 - > saved mIoU
2025-01-08 22:14:15,688 - 10       0.491877   0.556558   0.368972   0.000000   0.847511   1.0e-04 , 1.0e-05 
2025-01-08 22:14:15,688 - > saved mIoU
2025-01-08 22:20:49,943 - 11       0.483378   0.564049   0.372159   0.000000   0.849654   1.0e-04 , 1.0e-05 
2025-01-08 22:20:49,944 - > saved mIoU
2025-01-08 22:27:23,239 - 12       0.473471   0.564430   0.376302   0.000000   0.845821   1.0e-04 , 1.0e-05 
2025-01-08 22:27:23,239 - > saved mIoU
2025-01-08 22:33:57,494 - 13       0.464115   0.557832   0.377533   0.000000   0.851018   1.0e-04 , 1.0e-05 
2025-01-08 22:33:57,495 - > saved mIoU
2025-01-08 22:40:31,914 - 14       0.455140   0.559871   0.381733   0.000000   0.845876   1.0e-04 , 1.0e-05 
2025-01-08 22:40:31,914 - > saved mIoU
2025-01-08 22:40:32,472 - Fine del training

2025-01-08 22:40:32,765 - 
Caricati i pesi in: /raid/homespace/piecestola/space/ML4CV/results/train_3/ckpts/weights_mIoU_0.pt

2025-01-08 22:40:32,767 - Inizio del training
2025-01-08 22:40:32,767 - optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 0.0001
    maximize: False
    weight_decay: 0.0001

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 1e-05
    maximize: False
    weight_decay: 0.0001
)
2025-01-08 22:40:32,767 - loss:      CrossEntropyLoss()
2025-01-08 22:40:32,767 - epochs:    50
2025-01-08 22:40:32,767 - name:      weights_1

2025-01-08 22:56:38,429 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-08 22:56:38,430 - 0        0.403445   0.474790   0.425773   0.000000   0.893503   1.0e-04 , 1.0e-05 
2025-01-08 23:12:45,335 - 1        0.295413   0.394814   0.469932   0.000000   0.910721   1.0e-04 , 1.0e-05 
2025-01-08 23:12:45,335 - > saved mIoU
2025-01-08 23:28:52,959 - 2        0.239678   0.372763   0.491001   0.000000   0.921791   1.0e-04 , 1.0e-05 
2025-01-08 23:28:52,960 - > saved mIoU
2025-01-08 23:45:00,359 - 3        0.196416   0.365778   0.499695   0.000000   0.925710   1.0e-04 , 1.0e-05 
2025-01-08 23:45:00,360 - > saved mIoU
2025-01-09 00:01:08,866 - 4        0.172205   0.362735   0.518604   0.000000   0.925732   1.0e-04 , 1.0e-05 
2025-01-09 00:01:08,867 - > saved mIoU
2025-01-09 00:17:16,476 - 5        0.155312   0.383712   0.516466   0.000000   0.912467   1.0e-04 , 1.0e-05 
2025-01-09 00:33:23,363 - 6        0.142321   0.364555   0.539034   0.068113   0.932146   1.0e-04 , 1.0e-05 
2025-01-09 00:33:23,363 - > saved mIoU
2025-01-09 00:49:32,039 - 7        0.132055   0.375930   0.566643   0.199208   0.930451   1.0e-04 , 1.0e-05 
2025-01-09 00:49:32,040 - > saved mIoU
2025-01-09 01:05:40,028 - 8        0.123672   0.365648   0.569518   0.202231   0.929861   1.0e-04 , 1.0e-05 
2025-01-09 01:05:40,028 - > saved mIoU
2025-01-09 01:21:48,446 - 9        0.119345   0.401385   0.574531   0.215490   0.930831   1.0e-04 , 1.0e-05 
2025-01-09 01:21:48,446 - > saved mIoU
2025-01-09 01:37:55,451 - 10       0.112809   0.395659   0.591969   0.224776   0.928297   1.0e-04 , 1.0e-05 
2025-01-09 01:37:55,451 - > saved mIoU
2025-01-09 01:54:03,392 - 11       0.110247   0.388147   0.595204   0.255913   0.932346   5.0e-05 , 5.0e-06 
2025-01-09 01:54:03,392 - > saved mIoU
2025-01-09 02:10:10,759 - 12       0.107708   0.381424   0.605940   0.288154   0.930714   5.0e-05 , 5.0e-06 
2025-01-09 02:10:10,759 - > saved mIoU
2025-01-09 02:26:20,033 - 13       0.101927   0.366305   0.608662   0.284748   0.931570   5.0e-05 , 5.0e-06 
2025-01-09 02:26:20,034 - > saved mIoU
2025-01-09 02:42:28,121 - 14       0.097539   0.386117   0.603938   0.302790   0.924784   5.0e-05 , 5.0e-06 
2025-01-09 02:58:32,198 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-09 02:58:32,198 - 15       0.095703   0.371308   0.613530   0.298484   0.931245   5.0e-05 , 5.0e-06 
2025-01-09 02:58:32,198 - > saved mIoU
2025-01-09 03:14:40,308 - 16       0.093191   0.384495   0.612116   0.293895   0.932218   5.0e-05 , 5.0e-06 
2025-01-09 03:30:46,401 - 17       0.092988   0.401034   0.616237   0.319556   0.929637   2.5e-05 , 2.5e-06 
2025-01-09 03:30:46,401 - > saved mIoU
2025-01-09 03:46:54,288 - 18       0.090848   0.402568   0.614736   0.309317   0.927517   2.5e-05 , 2.5e-06 
2025-01-09 04:02:59,903 - 19       0.089099   0.411111   0.615347   0.330645   0.930520   2.5e-05 , 2.5e-06 
2025-01-09 04:19:06,068 - 20       0.086911   0.399936   0.615920   0.309359   0.929088   2.5e-05 , 2.5e-06 
2025-01-09 04:35:14,021 - 21       0.085675   0.395269   0.614657   0.313188   0.930772   2.5e-05 , 2.5e-06 
2025-01-09 04:51:22,454 - 22       0.083735   0.403273   0.623094   0.327264   0.931995   2.5e-05 , 2.5e-06 
2025-01-09 04:51:22,455 - > saved mIoU
2025-01-09 05:07:30,325 - 23       0.083918   0.403701   0.618301   0.312602   0.933256   1.3e-05 , 1.3e-06 
2025-01-09 05:23:36,574 - 24       0.082272   0.416109   0.616887   0.323613   0.933372   1.3e-05 , 1.3e-06 
2025-01-09 05:39:43,018 - 25       0.081096   0.422253   0.618310   0.314669   0.932727   1.3e-05 , 1.3e-06 
2025-01-09 05:55:48,441 - 26       0.080978   0.416731   0.621967   0.321228   0.932827   1.3e-05 , 1.3e-06 
2025-01-09 06:11:53,494 - 27       0.079449   0.410447   0.622176   0.318681   0.932706   1.3e-05 , 1.3e-06 
2025-01-09 06:28:00,669 - 28       0.079639   0.418825   0.620002   0.327967   0.933290   1.3e-05 , 1.3e-06 
2025-01-09 06:44:07,140 - 29       0.079207   0.412810   0.624113   0.325104   0.934554   6.3e-06 , 6.3e-07 
2025-01-09 06:44:07,140 - > saved mIoU
2025-01-09 07:00:13,289 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-09 07:00:13,290 - 30       0.078088   0.418656   0.623527   0.329333   0.933075   6.3e-06 , 6.3e-07 
2025-01-09 07:16:20,037 - 31       0.077362   0.408321   0.623985   0.329444   0.933030   6.3e-06 , 6.3e-07 
2025-01-09 07:32:24,972 - 32       0.077389   0.411593   0.626833   0.326716   0.933019   6.3e-06 , 6.3e-07 
2025-01-09 07:32:24,973 - > saved mIoU
2025-01-09 07:48:31,787 - 33       0.076466   0.412832   0.623663   0.330850   0.933677   6.3e-06 , 6.3e-07 
2025-01-09 08:04:36,779 - 34       0.076723   0.415315   0.622813   0.317871   0.933667   6.3e-06 , 6.3e-07 
2025-01-09 08:20:41,412 - 35       0.076096   0.413144   0.626823   0.325740   0.934527   3.1e-06 , 3.1e-07 
2025-01-09 08:36:47,380 - 36       0.076332   0.416972   0.624081   0.328884   0.933369   3.1e-06 , 3.1e-07 
2025-01-09 08:52:53,339 - 37       0.075381   0.415346   0.626446   0.331691   0.935636   3.1e-06 , 3.1e-07 
2025-01-09 09:08:58,526 - 38       0.075340   0.417115   0.626802   0.328147   0.933934   3.1e-06 , 3.1e-07 
2025-01-09 09:25:04,215 - 39       0.075013   0.412471   0.629485   0.327390   0.934732   3.1e-06 , 3.1e-07 
2025-01-09 09:25:04,215 - > saved mIoU
2025-01-09 09:41:11,806 - 40       0.075060   0.417936   0.625631   0.333520   0.934075   3.1e-06 , 3.1e-07 
2025-01-09 09:57:16,595 - 41       0.074591   0.414591   0.626546   0.332683   0.934463   1.6e-06 , 1.6e-07 
2025-01-09 10:13:20,544 - 42       0.075102   0.417357   0.626171   0.332390   0.934022   1.6e-06 , 1.6e-07 
2025-01-09 10:29:26,043 - 43       0.073830   0.415841   0.627155   0.330790   0.934313   1.6e-06 , 1.6e-07 
2025-01-09 10:45:32,448 - 44       0.074755   0.415164   0.625848   0.331556   0.934501   1.6e-06 , 1.6e-07 
2025-01-09 11:01:38,423 - Epoch    Loss       Val Loss   mIoU       minIoU     maxIoU     LR      
2025-01-09 11:01:38,424 - 45       0.074227   0.415907   0.625032   0.328527   0.933555   1.6e-06 , 1.6e-07 
2025-01-09 11:17:44,449 - 46       0.073957   0.414182   0.626691   0.329335   0.933957   1.6e-06 , 1.6e-07 
2025-01-09 11:33:49,161 - 47       0.073389   0.416414   0.625441   0.329947   0.932566   7.8e-07 , 7.8e-08 
2025-01-09 11:49:55,046 - 48       0.073934   0.416395   0.625303   0.331322   0.934440   7.8e-07 , 7.8e-08 
2025-01-09 12:06:00,410 - 49       0.073794   0.414738   0.625007   0.331741   0.933891   7.8e-07 , 7.8e-08 
2025-01-09 12:06:00,411 - Fine del training

