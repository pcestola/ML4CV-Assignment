{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1024, 2])\n",
      "torch.Size([1, 1024, 2])\n",
      "torch.Size([1, 1024, 2])\n",
      "torch.Size([1, 1024, 2])\n",
      "torch.Size([1, 1024, 2])\n",
      "torch.Size([1, 1024, 2])\n",
      "torch.Size([1, 1024, 2])\n",
      "torch.Size([1, 1024, 2])\n",
      "torch.Size([1, 1024, 2])\n",
      "torch.Size([1, 1024, 2])\n",
      "torch.Size([1, 1024, 2])\n",
      "torch.Size([1, 1024, 2])\n",
      "torch.Size([1, 1024, 2])\n",
      "torch.Size([1, 13, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MetricHead(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(MetricHead, self).__init__()\n",
    "        \n",
    "        # Riduzione a 2 canali con una convoluzione\n",
    "        self.conv = nn.Conv2d(in_channels, 2, kernel_size=1)\n",
    "        \n",
    "        # Vettori normalizzati da apprendere (13 vettori di 2 dimensioni)\n",
    "        self.learnable_vectors = nn.Parameter(torch.randn(13, 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Riduci i canali a 2 e normalizza\n",
    "        x = self.conv(x)  # (b, 2, h, w)\n",
    "        x = F.normalize(x, p=2, dim=1)\n",
    "\n",
    "        # Normalizza i vettori appresi direttamente nel forward\n",
    "        normalized_vectors = F.normalize(self.learnable_vectors, p=2, dim=1)\n",
    "\n",
    "        # Calcolo delle distanze rispetto ai vettori appresi\n",
    "        b, c, h, w = x.shape\n",
    "\n",
    "        # Risagomare per calcolare la distanza\n",
    "        x_flat = x.view(b, c, -1).permute(0, 2, 1)  # (b, h*w, 2)\n",
    "\n",
    "        # Calcola la distanza per ciascun vettore\n",
    "        distances = []\n",
    "        for v in normalized_vectors:\n",
    "            v = v.unsqueeze(0).expand(b, -1)\n",
    "            dist = torch.norm(x_flat - v, dim=2)\n",
    "            distances.append(dist.view(b, h, w))\n",
    "\n",
    "        # Stack delle distanze (b, 13, h, w)\n",
    "        distances = torch.stack(distances, dim=1)\n",
    "        return distances\n",
    "\n",
    "# Esempio di utilizzo\n",
    "model = MetricHead(in_channels=3)\n",
    "x = torch.randn(1, 3, 32, 32)\n",
    "distances = model(x)\n",
    "print(distances.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_metrics(log_file):\n",
    "    metrics = {}\n",
    "\n",
    "    for line in log_file.readlines():\n",
    "        if len(line):\n",
    "            tokens = line.split()\n",
    "            \n",
    "            # IoU metrics\n",
    "            if 'mIoU_no_zero:' in tokens:\n",
    "                metrics['mIoU'] = float(tokens[4])*100\n",
    "            elif 'classe' in tokens and '3:' in tokens:\n",
    "                metrics['minIoU'] = float(tokens[2])*100\n",
    "            elif 'maxIoU:' in tokens:\n",
    "                metrics['maxIoU'] = float(tokens[4])*100\n",
    "            # anomaly metrics\n",
    "            if 'AUPR:' in tokens:\n",
    "                metrics[tokens[3].lower()] = float(tokens[5])*100\n",
    "    return metrics\n",
    "\n",
    "def find_parameters(log_file):\n",
    "    params = {}\n",
    "\n",
    "    flag = True\n",
    "    for line in log_file.readlines():\n",
    "        if len(line):\n",
    "            tokens = line.split()\n",
    "            \n",
    "            if flag:\n",
    "                if 'Dataset' in tokens:\n",
    "                    flag = False\n",
    "                else:\n",
    "                    params[tokens[3]] = tokens[5]\n",
    "            else:\n",
    "                break\n",
    "    return params\n",
    "\n",
    "def prepare_metrics(metrics):\n",
    "    stringa = ''\n",
    "    stringa += f\"{round(metrics['mIoU'],2)};\"\n",
    "    stringa += f\"{round(metrics['minIoU'],2)};\"\n",
    "    stringa += f\"{round(metrics['maxIoU'],2)};\"\n",
    "    stringa += f\"{round(metrics['msp'],2)};\"\n",
    "    stringa += f\"{round(metrics['maxlog'],2)};\"\n",
    "    stringa += f\"{round(metrics['entropy'],2)};\"\n",
    "    stringa += f\"{round(metrics['energy'],2)}\"\n",
    "    return stringa.replace('.',',')\n",
    "\n",
    "def prepare_parameters(parameters):\n",
    "    mappa = {'True': '✓', 'False': '𐄂'}\n",
    "\n",
    "    stringa = ''\n",
    "    stringa += f\"{mappa[parameters['biases']]};\"\n",
    "    stringa += f\"{mappa[str(bool(int(parameters['focal_loss'])))]};\"\n",
    "    stringa += f\"{mappa[parameters['class_weights']]};\"\n",
    "    stringa += f\"{mappa[parameters['norm_weights']]};\"\n",
    "    try:\n",
    "        stringa += f\"{mappa[str(bool(int(parameters['mlp'])))]};\"\n",
    "    except:\n",
    "        stringa += f\"{mappa['False']};\"\n",
    "    stringa += f\"{parameters['activation']};\"\n",
    "    return stringa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letti correttamente: 1 4 5 6 7 8 9 10 \n",
      "\n",
      "\\begin{array}{|cccccc|ccc|cccccc|}\n",
      "\\hline\n",
      "\\text{Biases} & \\text{Focal Loss} & \\text{Class weights} & \\text{Norm weights} & \\text{MLP} & \\text{Activation} & \\text{mIoU} & \\text{minIoU} & \\text{maxIoU} & \\text{msp} & \\text{maxlogit} & \\text{entropy} & \\text{energy} \\\\\n",
      "\\hline\n",
      "𐄂 & 𐄂 & 𐄂 & 𐄂 & 𐄂 & \\text{softmax} & \\underline{65,41} & \\underline{10,97} & \\underline{97,16} & 10,79 & \\underline{15,38} & \\underline{13,71} & \\underline{15,69} \\\\\n",
      "𐄂 & 𐄂 & 𐄂 & 𐄂 & 𐄂 & \\text{softmax} & 59,93 & 8,44 & 96,15 & 9,68 & 11,69 & 11,5 & 11,55 \\\\\n",
      "𐄂 & 𐄂 & 𐄂 & 𐄂 & 𐄂 & \\text{sigmoid} & 57,49 & 8,42 & 96,0 & 7,41 & 7,59 & 8,5 & 7,21 \\\\\n",
      "𐄂 & 𐄂 & 𐄂 & ✓ & 𐄂 & \\text{softmax} & 50,61 & 4,23 & 95,1 & 10,14 & 3,1 & 8,24 & 0,54 \\\\\n",
      "𐄂 & 𐄂 & 𐄂 & ✓ & 𐄂 & \\text{softmax} & 48,49 & 3,69 & 96,1 & 8,69 & 3,54 & 3,3 & 0,56 \\\\\n",
      "𐄂 & 𐄂 & ✓ & ✓ & 𐄂 & \\text{softmax} & 36,4 & 3,34 & 91,81 & 3,53 & 2,94 & 5,32 & 0,78 \\\\\n",
      "𐄂 & 𐄂 & 𐄂 & ✓ & 𐄂 & \\text{softmax} & 60,86 & 9,24 & 96,27 & \\underline{11,03} & 1,52 & 7,0 & 0,58 \\\\\n",
      "𐄂 & 𐄂 & ✓ & ✓ & 𐄂 & \\text{softmax} & 54,8 & 8,02 & 93,17 & 7,46 & 1,03 & 5,16 & 0,57 \\\\\n",
      "\\hline\n",
      "\\end{array}\n"
     ]
    }
   ],
   "source": [
    "folder = '/raid/homespace/piecestola/space/ML4CV/results_7'\n",
    "\n",
    "texts = list()\n",
    "order = list()\n",
    "for file in os.listdir(folder):\n",
    "    try:\n",
    "        path_train = os.path.join(folder,file,'train.log')\n",
    "        path_test = os.path.join(folder,file,'test.log')\n",
    "        \n",
    "        params = find_parameters(open(path_train,'r'))\n",
    "        metrics = find_metrics(open(path_test,'r'))\n",
    "\n",
    "        params = prepare_parameters(params)\n",
    "        metrics = prepare_metrics(metrics)\n",
    "\n",
    "        order.append(int(file.split('_')[1]))\n",
    "\n",
    "        text = params+metrics\n",
    "        text = text.replace(';',' & ')\n",
    "        text = text.replace('softmax','\\\\text{softmax}')\n",
    "        text = text.replace('sigmoid','\\\\text{sigmoid}')\n",
    "        text += ' \\\\\\\\'\n",
    "        texts.append(text)\n",
    "    except:\n",
    "        print(\"Skipped\",file)\n",
    "\n",
    "texts = [v for _, v in sorted(zip(order, texts))]\n",
    "\n",
    "print('Letti correttamente:',end=' ')\n",
    "for k, v in sorted(zip(order, texts)):\n",
    "    print(k,end=' ')\n",
    "print('\\n')\n",
    "\n",
    "print('\\\\begin{array}{|cccccc|ccc|cccccc|}')\n",
    "print('\\\\hline')\n",
    "print('\\\\text{Biases} & \\\\text{Focal Loss} & \\\\text{Class weights} & \\\\text{Norm weights} & \\\\text{MLP} & \\\\text{Activation} & \\\\text{mIoU} & \\\\text{minIoU} & \\\\text{maxIoU} & \\\\text{msp} & \\\\text{maxlogit} & \\\\text{entropy} & \\\\text{energy} \\\\\\\\')\n",
    "print('\\\\hline')\n",
    "\n",
    "maxs = [0,0,0,0,0,0,0]\n",
    "maxs_id = [0,0,0,0,0,0,0]\n",
    "for i, text in enumerate(texts):\n",
    "    tokens = text.split()\n",
    "    for j in range(12,26,2):\n",
    "        temp = float(tokens[j].replace(',','.'))\n",
    "        if temp > maxs[j//2-6]:\n",
    "            maxs[j//2-6] = temp\n",
    "            maxs_id[j//2-6] = i\n",
    "\n",
    "for i, text in enumerate(texts):\n",
    "    tokens = text.split()\n",
    "    for k, id in enumerate(maxs_id):\n",
    "        if id == i:\n",
    "            tokens[(k+6)*2] = '\\\\underline{'+tokens[(k+6)*2]+'}'\n",
    "    print(' '.join(tokens))\n",
    "\n",
    "print('\\\\hline')\n",
    "print('\\\\end{array}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
